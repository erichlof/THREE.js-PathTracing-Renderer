<!DOCTYPE html>
<html lang="en">

<head>
	<title>three.js PathTracing Renderer - BVH / GLTF Model Loading</title>
	<meta charset="utf-8">
	<meta name="viewport" content="width=device-width, user-scalable=no, initial-scale=1">
	<style>

		html, body {
				width: 100%;
				height: 100%;
				font-family: Monospace;
				background-color: #000;
				color: #000;
				margin: 0px;
				overflow: hidden;
				touch-action: none;
			}
			
			#info {
				position: absolute;
				top: 5px;
				width: 100%;
				text-align: center;
				color: #ffffff;
			}		
			
		</style>
</head>

<body>

	<div id="container"> </div>
	<div id="info">three.js PathTracing Renderer - BVH / GLTF Model Loading</div>

	<div id="cameraInfo" style="position:fixed; left:3%; bottom:2%; font-family:arial; color:rgb(255,255,255);">
		FOV: 72 / Aperture: 0.00 / FocusDistance: 100 <br>
		Samples: 0
	</div>

	<script src="js/three.min.js"> </script>
	<script src="js/BufferGeometryUtils.js"> </script>
	<script src="js/GLTFLoader.js"></script>
	<script src="js/BVH_Acc_Structure_Iterative_Builder.js"> </script>
	<script src="js/pathTracingCommon.js"> </script>
	<script src="js/threex.keyboardstate.js"> </script>
	<script src="js/FirstPersonCameraControls.js"> </script>
	<script src="js/MobileJoystickControls.js"> </script>
	<script src="js/stats.min.js"> </script>


	<script id="pathTracingVertexShader" type="x-shader/x-vertex">
#version 300 es

precision highp float;
precision highp int;

out vec2 vUv;

void main()
{
	vUv = uv;
	gl_Position = vec4( position, 1.0 );
}

		</script>



	<script id="pathTracingFragmentShader" type="x-shader/x-fragment">
#version 300 es

precision highp float;
precision highp int;
precision highp sampler2D;

#include <pathtracing_uniforms_and_defines>

uniform sampler2D tTriangleTexture;
uniform sampler2D tAABBTexture;
uniform sampler2D tAlbedoTextures[8]; // 8 = max number of diffuse albedo textures per model

//float InvTextureWidth = 0.000244140625; // (1 / 4096 texture width)
//float InvTextureWidth = 0.00048828125;  // (1 / 2048 texture width)
//float InvTextureWidth = 0.0009765625;   // (1 / 1024 texture width)

#define INV_TEXTURE_WIDTH 0.00048828125

#define N_SPHERES 5
#define N_BOXES 2

//-----------------------------------------------------------------------

struct Ray { vec3 origin; vec3 direction; };
struct Sphere { float radius; vec3 position; vec3 emission; vec3 color; int type; };
struct Box { vec3 minCorner; vec3 maxCorner; vec3 emission; vec3 color; int type; };
struct Intersection { vec3 normal; vec3 emission; vec3 color; vec2 uv; int type; int albedoTextureID; };

Sphere spheres[N_SPHERES];
Box boxes[N_BOXES];


#include <pathtracing_random_functions>

#include <pathtracing_calc_fresnel_reflectance>

#include <pathtracing_sphere_intersect>

#include <pathtracing_box_intersect>

#include <pathtracing_boundingbox_intersect>

#include <pathtracing_bvhTriangle_intersect>

struct StackLevelData
{
        float id;
        float rayT;
} stackLevels[24];

struct BoxNode
{
	float branch_A_Index;
	vec3 minCorner;
	float branch_B_Index;
	vec3 maxCorner;  
};

BoxNode GetBoxNode(const in float i)
{
	// each bounding box's data is encoded in 2 rgba(or xyzw) texture slots 
	float iX2 = (i * 2.0);
	// (iX2 + 0.0) corresponds to .x: idLeftChild, .y: aabbMin.x, .z: aabbMin.y, .w: aabbMin.z 
	// (iX2 + 1.0) corresponds to .x: idRightChild .y: aabbMax.x, .z: aabbMax.y, .w: aabbMax.z 
	
	vec2 uv0 = vec2( (mod(iX2 + 0.0, 2048.0)), floor((iX2 + 0.0) * INV_TEXTURE_WIDTH) ) * INV_TEXTURE_WIDTH;
	vec2 uv1 = vec2( (mod(iX2 + 1.0, 2048.0)), floor((iX2 + 1.0) * INV_TEXTURE_WIDTH) ) * INV_TEXTURE_WIDTH;

	vec4 aabbNodeData0 = texture( tAABBTexture, uv0 );
	vec4 aabbNodeData1 = texture( tAABBTexture, uv1 );

	BoxNode BN = BoxNode( aabbNodeData0.x,
			      aabbNodeData0.yzw,
			      aabbNodeData1.x,
			      aabbNodeData1.yzw );

        return BN;
}

//----------------------------------------------------------
float SceneIntersect( Ray r, inout Intersection intersec )
//----------------------------------------------------------
{
	vec3 n;
	float d = INFINITY;
	float t = INFINITY;
		
	// AABB BVH Intersection variables
	vec4 aabbNodeData0, aabbNodeData1, aabbNodeData2;
	vec4 vd0, vd1, vd2, vd3, vd4, vd5, vd6, vd7;
	vec3 aabbMin, aabbMax;
	vec3 inverseDir = 1.0 / r.direction;
	vec2 uv0, uv1, uv2, uv3, uv4, uv5, uv6, uv7;
        float stackptr = 0.0;	
	float bc, bd;
	float id = 0.0;
	float tw, tu, tv;
        
	bool skip = false;

	
	// first intersect rood node (index 0.0), and save result into currentStackData
	BoxNode currentBoxNode = GetBoxNode(0.0);
        StackLevelData currentStackData = 
           StackLevelData(0.0, BoundingBoxIntersect(currentBoxNode.minCorner, currentBoxNode.maxCorner, r.origin, inverseDir));
        
        for (int g = 0; g == 0; g += 0) // infinite loop with break condition, mimics 'while' loop
        {
                if (currentStackData.rayT < t) // is current t < closest t stored so far?
                {
                        if (currentBoxNode.branch_A_Index < 0.0) //  < 0.0 signifies a leaf node
                        {
				// each triangle's data is encoded in 8 rgba(or xyzw) texture slots
				id = 8.0 * (-currentBoxNode.branch_A_Index - 1.0);
				uv0 = vec2( (mod(id + 0.0, 2048.0)), floor((id + 0.0) * INV_TEXTURE_WIDTH) ) * INV_TEXTURE_WIDTH;
				uv1 = vec2( (mod(id + 1.0, 2048.0)), floor((id + 1.0) * INV_TEXTURE_WIDTH) ) * INV_TEXTURE_WIDTH;
				uv2 = vec2( (mod(id + 2.0, 2048.0)), floor((id + 2.0) * INV_TEXTURE_WIDTH) ) * INV_TEXTURE_WIDTH;
				uv3 = vec2( (mod(id + 3.0, 2048.0)), floor((id + 3.0) * INV_TEXTURE_WIDTH) ) * INV_TEXTURE_WIDTH;
				uv4 = vec2( (mod(id + 4.0, 2048.0)), floor((id + 4.0) * INV_TEXTURE_WIDTH) ) * INV_TEXTURE_WIDTH;
				uv5 = vec2( (mod(id + 5.0, 2048.0)), floor((id + 5.0) * INV_TEXTURE_WIDTH) ) * INV_TEXTURE_WIDTH;
				uv6 = vec2( (mod(id + 6.0, 2048.0)), floor((id + 6.0) * INV_TEXTURE_WIDTH) ) * INV_TEXTURE_WIDTH;
				uv7 = vec2( (mod(id + 7.0, 2048.0)), floor((id + 7.0) * INV_TEXTURE_WIDTH) ) * INV_TEXTURE_WIDTH;
				
				vd0 = texture( tTriangleTexture, uv0 );	      
				vd1 = texture( tTriangleTexture, uv1 );	      
				vd2 = texture( tTriangleTexture, uv2 );
				vd3 = texture( tTriangleTexture, uv3 );	      
				vd4 = texture( tTriangleTexture, uv4 );
				vd5 = texture( tTriangleTexture, uv5 );
				vd6 = texture( tTriangleTexture, uv6 );
				vd7 = texture( tTriangleTexture, uv7 );

				d = BVH_TriangleIntersect( vec3(vd0.xyz), vec3(vd0.w, vd1.xy), vec3(vd1.zw, vd2.x), r, tu, tv );

				if (d < t && d > 0.0)
				{
					t = d;
					// face normal for flat-shaded polygon look
					//intersec.normal = normalize( cross(vec3(vd0.w, vd1.xy) - vec3(vd0.xyz), vec3(vd1.zw, vd2.x) - vec3(vd0.xyz)) );
					
					// interpolated normal using triangle intersection's uv's
					tw = 1.0 - tu - tv;
					intersec.normal = normalize(tw * vec3(vd2.yzw) + tu * vec3(vd3.xyz) + tv * vec3(vd3.w, vd4.xy));
					intersec.emission = vec3(1, 0, 1); // use this if intersec.type will be LIGHT
					intersec.color = vd6.yzw;
					intersec.uv = tw * vec2(vd4.zw) + tu * vec2(vd5.xy) + tv * vec2(vd5.zw);
					intersec.type = int(vd6.x);
					intersec.albedoTextureID = int(vd7.x);
				}
                        }
                        else // else this is a branch
                        {
                                BoxNode nodeA = GetBoxNode(currentBoxNode.branch_A_Index);
                                BoxNode nodeB = GetBoxNode(currentBoxNode.branch_B_Index);
                                StackLevelData slDataA = StackLevelData(currentBoxNode.branch_A_Index, BoundingBoxIntersect(nodeA.minCorner, nodeA.maxCorner, r.origin, inverseDir));
                                StackLevelData slDataB = StackLevelData(currentBoxNode.branch_B_Index, BoundingBoxIntersect(nodeB.minCorner, nodeB.maxCorner, r.origin, inverseDir));
				
				// first sort the branch node data so that b is smallest
                                if (slDataA.rayT < slDataB.rayT)
                                {
                                        StackLevelData tmp = slDataA;
                                        slDataA = slDataB;
                                        slDataB = tmp;

                                        BoxNode tnp = nodeA;
                                        nodeA = nodeB;
                                        nodeB = tnp;
				} // branch 'a' now has the larger rayT value of 'a' and 'b'
				
                                if (slDataA.rayT < t) // see if branch 'a' needs to be processed
                                {
                                        currentStackData = slDataA;
                                        currentBoxNode = nodeA;
                                        skip = true; // this will prevent the stackptr from decreasing by 1
                                }
                                if (slDataB.rayT < t) // see if branch 'b' (the smaller rayT) needs to be processed 
                                {
                                        if (skip == true) // if 'a' needed to be processed also,
                                                stackLevels[int(stackptr++)] = slDataA; // cue larger branch 'a' for future round
                                                                // also, increase pointer by 1
                                        currentStackData = slDataB;
                                        currentBoxNode = nodeB;
                                        skip = true; // this will prevent the stackptr from decreasing by 1
                                }
                        }
		} // end if (currentStackData.rayT < t)
		
                if (skip == false) // if no valid aabb intersections were found, backtrack 
                {
                        // decrease pointer by 1 (0.0 is root level, 32.0 is maximum depth)
                        if (--stackptr < 0.0) // went past the root level, terminate loop
                                break;
                        currentStackData = stackLevels[int(stackptr)];
                        currentBoxNode = GetBoxNode(currentStackData.id);
                }
		skip = false; // reset skip
		
        } // end for (int g = 0; g == 0; g += 0)


        for (int i = 0; i < N_SPHERES; i++)
        {
		d = SphereIntersect( spheres[i].radius, spheres[i].position, r );
		if (d < t)
		{
			t = d;
			intersec.normal = (r.origin + r.direction * t) - spheres[i].position;
			intersec.emission = spheres[i].emission;
			intersec.color = spheres[i].color;
			intersec.type = spheres[i].type;
			intersec.albedoTextureID = -1;
		}
        }
	
	for (int i = 0; i < N_BOXES; i++)
        {
		d = BoxIntersect( boxes[i].minCorner, boxes[i].maxCorner, r, n );
		if (d < t)
		{
			t = d;
			intersec.normal = normalize(n);
			intersec.emission = boxes[i].emission;
			intersec.color = boxes[i].color;
			intersec.type = boxes[i].type;
			intersec.albedoTextureID = -1;
		}
        }
	
	return t;

} // end float SceneIntersect( Ray r, inout Intersection intersec )


//-----------------------------------------------------------------------
vec3 CalculateRadiance( Ray r, inout uvec2 seed )
//-----------------------------------------------------------------------
{
	Intersection intersec;
	vec3 accumCol = vec3(0.0);
        vec3 mask = vec3(1.0);
	vec3 checkCol0 = vec3(1);
	vec3 checkCol1 = vec3(0.5);
        vec3 tdir;
	
	float nc, nt, Re;
        float epsIntersect = 0.01;
        
	bool bounceIsSpecular = true;
        
	
        for (int depth = 0; depth < 5; depth++)
	{

		float t = SceneIntersect(r, intersec);
		
		if (t == INFINITY)
		{
                        break;
		}
		
		// if we reached something bright, don't spawn any more rays
		if (intersec.type == LIGHT)
		{	
			//if (bounceIsSpecular)
			{
				accumCol = mask * intersec.emission;
			}
			
			break;
		}
		
		
		// useful data 
		vec3 n = intersec.normal;
                vec3 nl = dot(n,r.direction) <= 0.0 ? normalize(n) : normalize(n * -1.0);
		vec3 x = r.origin + r.direction * t;
		
		    
                if (intersec.type == DIFF || intersec.type == CHECK) // Ideal DIFFUSE reflection
                {
			if( intersec.type == CHECK )
			{
				float q = clamp( mod( dot( floor(x.xz * 0.04), vec2(1.0) ), 2.0 ) , 0.0, 1.0 );
				intersec.color = checkCol0 * q + checkCol1 * (1.0 - q);	
			}
			
			mask *= intersec.color;
			bounceIsSpecular = false;

			// Russian Roulette
			float p = max(mask.r, max(mask.g, mask.b));
			if (depth > 0)
			{
				if (rand(seed) < p)
                                	mask *= 1.0 / p;
                        	else
                                	break;
			}
                        
			// choose random Diffuse sample vector
			r = Ray( x, randomCosWeightedDirectionInHemisphere(nl, seed) );
			r.origin += r.direction * epsIntersect;
			continue;	
                }
		
                if (intersec.type == SPEC)  // Ideal SPECULAR reflection
                {
			r = Ray( x, reflect(r.direction, nl) );
			r.origin += r.direction * epsIntersect;
			mask *= intersec.color;
			bounceIsSpecular = true;
                        continue;
                }

                if (intersec.type == REFR)  // Ideal dielectric REFRACTION
		{
			nc = 1.0; // IOR of Air
			nt = 1.5; // IOR of common Glass
			Re = calcFresnelReflectance(n, nl, r.direction, nc, nt, tdir);

			//if (diffuseCount < 2)
				bounceIsSpecular = true;
			
			if (rand(seed) < Re) // reflect ray from surface
			{
				r = Ray( x, reflect(r.direction, nl) );
				r.origin += r.direction * epsIntersect;
			    	continue;	
			}
			else // transmit ray through surface
			{
				mask *= intersec.color;
				r = Ray(x, tdir);
				r.origin += r.direction * epsIntersect;
				continue;
			}

		} // end if (intersec.type == REFR)
		
		if (intersec.type == COAT)  // Diffuse object underneath with ClearCoat on top (like car, or shiny pool ball)
		{
			nc = 1.0; // IOR of Air
			nt = 1.4; // IOR of ClearCoat
			Re = calcFresnelReflectance(n, nl, r.direction, nc, nt, tdir);
			
			// choose either specular reflection or diffuse
			if( rand(seed) < Re )
			{	
				r = Ray( x, reflect(r.direction, nl) );
				r.origin += r.direction * epsIntersect;
				bounceIsSpecular = true;
				continue;	
			}
			else
			{
				mask *= intersec.color;
				int id = intersec.albedoTextureID;
				if (id > -1)
				{
					vec3 albedoSample;
					     if (id == 0) albedoSample = texture(tAlbedoTextures[0], intersec.uv).rgb;
					else if (id == 1) albedoSample = texture(tAlbedoTextures[1], intersec.uv).rgb;
					else if (id == 2) albedoSample = texture(tAlbedoTextures[2], intersec.uv).rgb;
					else if (id == 3) albedoSample = texture(tAlbedoTextures[3], intersec.uv).rgb;
					else if (id == 4) albedoSample = texture(tAlbedoTextures[4], intersec.uv).rgb;
					else if (id == 5) albedoSample = texture(tAlbedoTextures[5], intersec.uv).rgb;
					else if (id == 6) albedoSample = texture(tAlbedoTextures[6], intersec.uv).rgb;
					else if (id == 7) albedoSample = texture(tAlbedoTextures[7], intersec.uv).rgb;

					mask *= albedoSample;
				}
				
				r = Ray( x, randomCosWeightedDirectionInHemisphere(nl, seed) );
				r.origin += r.direction * epsIntersect;
				bounceIsSpecular = false;
				continue;
			}
			
		} //end if (intersec.type == COAT)
		
		
	} // end for (int depth = 0; depth < 5; depth++)
	
	return accumCol;      
}


//-----------------------------------------------------------------------
void SetupScene(void)
//-----------------------------------------------------------------------
{
	vec3 z  = vec3(0);          
	vec3 L3 = vec3(1, 0.984, 0.941);// yellowish light
	
	spheres[0] = Sphere( 10000.0,     vec3(0, 0, 0), L3,                 z, LIGHT);//spherical white Light1
	spheres[1] = Sphere(  4000.0, vec3(0, -4000, 0),  z, vec3(0.4,0.4,0.4), CHECK);//Checkered Floor
	//spheres[2] = Sphere(     6.0, vec3(55, 36, -45),  z,         vec3(0.9),  SPEC);//small mirror ball
	//spheres[3] = Sphere(     6.0, vec3(55, 24, -45),  z, vec3(0.5,1.0,1.0),  REFR);//small glass ball
	//spheres[4] = Sphere(     6.0, vec3(60, 24, -30),  z,         vec3(1.0),  COAT);//small plastic ball
		
	//boxes[0] = Box( vec3(-20.0,11.0,-110.0), vec3(70.0,18.0,-20.0), z, vec3(0.2,0.9,0.7), REFR);//Glass Box
	//boxes[1] = Box( vec3(-14.0,13.0,-104.0), vec3(64.0,16.0,-26.0), z, vec3(0),           DIFF);//Inner Box
}


#include <pathtracing_main>


		</script>



	<script>
		var SCREEN_WIDTH;
		var SCREEN_HEIGHT;
		var canvas, context;
		var container, stats;
		var controls;
		var pathTracingScene, screenTextureScene, screenOutputScene;
		var pathTracingUniforms, screenTextureUniforms, screenOutputUniforms;
		var pathTracingDefines;
		var pathTracingGeometry, pathTracingMaterial, pathTracingMesh;
		var screenTextureGeometry, screenTextureMaterial, screenTextureMesh;
		var screenOutputGeometry, screenOutputMaterial, screenOutputMesh;
		var pathTracingRenderTarget, screenOutputRenderTarget;
		var quadCamera, worldCamera;
		var renderer, clock;
		var frameTime, elapsedTime;
		var fovScale;
		var increaseFOV = false;
		var decreaseFOV = false;
		var apertureSize = 0.0;
		var increaseAperture = false;
		var decreaseAperture = false;
		var focusDistance = 100.0;
		var increaseFocusDist = false;
		var decreaseFocusDist = false;
		var pixelRatio = 1;
		var TWO_PI = Math.PI * 2;
		var randomVector = new THREE.Vector3();
		var sampleCounter = 1.0;
		var frameCounter = 1.0;
		var keyboard = new THREEx.KeyboardState();
		var cameraIsMoving = false;
		var cameraJustStartedMoving = false;
		var cameraRecentlyMoving = false;
		var isPaused = true;
		var oldYawRotation, oldPitchRotation;
		var mobileJoystickControls = null;
		var oldDeltaX = 0,
			oldDeltaY = 0;
		var newDeltaX = 0,
			newDeltaY = 0;
		var mobileControlsMoveX = 0;
		var mobileControlsMoveY = 0;
		var stillFlagX = true,
			stillFlagY = true;
		var oldPinchWidthX = 0;
		var oldPinchWidthY = 0;
		var pinchDeltaX = 0;
		var pinchDeltaY = 0;
		var camFlightSpeed = 60;
		var fontAspect;
		var modelMesh;
		var modelScale = 1.0;
		var modelPositionOffset = new THREE.Vector3();
		var albedoTexture;
		var total_number_of_triangles = 0;
		var triangle_array;
		var triangleMaterialMarkers = [];
		var pathTracingMaterialList = [];
		var uniqueMaterialTextures = [];
		var meshList = [];
		var triangleDataTexture;
		var aabb_array;
		var aabbDataTexture;
		var totalWork;
		var vp0 = new THREE.Vector3();
		var vp1 = new THREE.Vector3();
		var vp2 = new THREE.Vector3();
		var vn0 = new THREE.Vector3();
		var vn1 = new THREE.Vector3();
		var vn2 = new THREE.Vector3();
		var vt0 = new THREE.Vector2();
		var vt1 = new THREE.Vector2();
		var vt2 = new THREE.Vector2();
		var myCounter= 0;

		// the following variables will be used to calculate rotations and directions from the camera
		var cameraDirectionVector = new THREE.Vector3(); //for moving where the camera is looking
		var cameraRightVector = new THREE.Vector3(); //for strafing the camera right and left
		var cameraUpVector = new THREE.Vector3(); //for moving camera up and down
		var cameraWorldQuaternion = new THREE.Quaternion(); //for rotating scene objects to match camera's current rotation
		var cameraControlsObject; //for positioning and moving the camera itself
		var cameraControlsYawObject; //allows access to control camera's left/right movements through mobile input
		var cameraControlsPitchObject; //allows access to control camera's up/down movements through mobile input

		var PI_2 = Math.PI / 2; //used by controls below

		var infoElement = document.getElementById('info');
		infoElement.style.cursor = "default";
		infoElement.style.webkitUserSelect = "none";
		infoElement.style.MozUserSelect = "none";

		var cameraInfoElement = document.getElementById('cameraInfo');
		cameraInfoElement.style.cursor = "default";
		cameraInfoElement.style.webkitUserSelect = "none";
		cameraInfoElement.style.MozUserSelect = "none";

		var mouseControl = true;

		function onMouseWheel(event) {

			event.preventDefault();
			event.stopPropagation();

			if (event.deltaY > 0) {

				increaseFOV = true;

			} else if (event.deltaY < 0) {

				decreaseFOV = true;

			}

		}

		function MaterialObject() {
		// a list of material types and their corresponding numbers are found in the 'pathTracingCommon.js' file
			this.type = 1; // default is '1': diffuse type 		
			this.albedoTextureID = -1; // which diffuse map to use for model's color / '-1' = no textures are used
			this.color = new THREE.Color(1.0, 1.0, 1.0); // takes on different meanings, depending on 'type' above
			this.roughness = 0.0; // 0.0 to 1.0 range, perfectly smooth to extremely rough
			this.metalness = 0.0; // 0.0 to 1.0 range, usually either 0 or 1, either non-metal or metal
			this.opacity = 1.0;   // 0.0 to 1.0 range, fully transparent to fully opaque
			this.refractiveIndex = 1.0; // 1.0=air, 1.33=water, 1.4=clearCoat, 1.5=glass, etc.
		}
		

		/*
		// when you uncomment a different model loading directive, it is suggested
		// to uncomment the matching settings for the model that you want to load
		var objLoader = new THREE.OBJLoader();
		var mtlLoader = new THREE.MTLLoader();

		//mtlLoader.load('models/materials/classic-1982-tron-cycle/classic-1982-tron-cycle.mtl', onLoadMtl);
		mtlLoader.load('models/materials/male02/male02.mtl', onLoadMtl);

		function onLoadMtl(materials) {

			materials.preload();
			objLoader.setMaterials(materials);

			//objLoader.load("models/classic-1982-tron-cycle.obj", function( meshGroup ) { // Triangles: 2,342
			objLoader.load("models/male02.obj", function( meshGroup ) { // Triangles: 5,004

				if (meshGroup.scene) 
					meshGroup = meshGroup.scene;

				meshGroup.traverse( function ( child ) {

					if ( child.isMesh ) {
						
						let mat = new MaterialObject();
						mat.type = 5;
						mat.color.copy(child.material.color);
						mat.albedoTextureID = -1;
						mat.roughness = 0.0;
						mat.metalness = 0.0;
						mat.opacity = 1.0;
						mat.refractiveIndex = 1.0;
						pathTracingMaterialList.push(mat);
						triangleMaterialMarkers.push(child.geometry.attributes.position.array.length / 9);
						meshList.push(child);
					}
				} );

				modelMesh = meshList[0].clone();

				for (let i = 1; i < triangleMaterialMarkers.length; i++) {
					triangleMaterialMarkers[i] += triangleMaterialMarkers[i-1];
				}
				
				var geoList = [];
				for (let i = 0; i < meshList.length; i++) {
					geoList.push(meshList[i].geometry);
				}
				
				modelMesh.geometry = THREE.BufferGeometryUtils.mergeBufferGeometries(geoList);
				if (modelMesh.geometry.index)
					modelMesh.geometry = modelMesh.geometry.toNonIndexed();
				
				for (let i = 0; i < meshList.length; i++) {
					if (meshList[i].material.map != undefined)
						uniqueMaterialTextures.push(meshList[i].material.map);		
				}

				for (let i = 0; i < uniqueMaterialTextures.length; i++) {
					for (let j = i + 1; j < uniqueMaterialTextures.length; j++) {
						if (uniqueMaterialTextures[i].image.src == uniqueMaterialTextures[j].image.src) {
							uniqueMaterialTextures.splice(j, 1);
							j -= 1;
						}
					}	
				}
				
				for (let i = 0; i < meshList.length; i++) {
					if (meshList[i].material.map != undefined) {
						for (let j = 0; j < uniqueMaterialTextures.length; j++) {
							if (meshList[i].material.map.image.src == uniqueMaterialTextures[j].image.src) {
								pathTracingMaterialList[i].albedoTextureID = j;
							}
						}
					}
								
				}

				// ********* different OBJ Model Settings **********

				// settings for classic 1982 Tron cycle model
				//modelScale = 27.0;
				//modelMesh.geometry.rotateY(Math.PI);
				//modelMesh.geometry.rotateX(-0.02);
				//modelPositionOffset.set(-70, -0.8, -70);

				// settings for male02 model
				modelScale = 0.3;
				modelPositionOffset.set(-50, 0, -40);

				
				// now that the models have been loaded, we can init everything else
				init();
			});
		} // end function onLoadMtl(materials)
		*/
		
		
		
		// when you uncomment a different model loading directive, it is suggested
		// to uncomment the matching settings for the model that you want to load
		var gltfLoader = new THREE.GLTFLoader();

		//gltfLoader.load("models/Duck.gltf", function( meshGroup ) { // Triangles: 4,212
		//gltfLoader.load("models/damagedHelmet.gltf", function( meshGroup ) { // Triangles: 15,452
		gltfLoader.load("models/00_003_002.gltf", function( meshGroup ) { // Triangles: 60
			if (meshGroup.scene)
				meshGroup = meshGroup.scene;
				
            let matrixStack = [];
            let parent;
            matrixStack.push(new THREE.Matrix4());
            meshGroup.traverse( function ( child ) {
                if ( child.isMesh ) {
                    let hasUVs = child.geometry.attributes.uv !== undefined ? 3 : 0
                    let hasNormals = child.geometry.attributes.normal !== undefined ? 3 : 0
                    //console.log(3 + hasUVs + hasNormals);
                    
                    if ( parent !== undefined && parent.name !== child.parent.name ) {
                        matrixStack.pop();
                        parent = undefined;
                    }
                    
                    child.geometry.applyMatrix( child.matrix.multiply( matrixStack[matrixStack.length - 1] ) );
                    let mat = new MaterialObject();
                    let materialType = child.material.opacity < 1 ? 2 : 4; // 2 = glossy transparent, 4 = glossy opaque
                    mat.type = materialType;
                    mat.color.copy(child.material.color);
                    mat.roughness = child.material.roughness || 0.0;
                    mat.metalness = child.material.metalness || 0.0;
                    mat.opacity = child.material.opacity || 1.0;
                    mat.refractiveIndex = materialType == 4 ? 1.0 : 1.52; // glass
                    console.log((3 + hasUVs + hasNormals));
                    pathTracingMaterialList.push(mat);
                    triangleMaterialMarkers.push(child.geometry.attributes.position.array.length / 9);
                    meshList.push(child);
                }
                else if ( child.isObject3D ) {
                    if ( parent !== undefined )
                        matrixStack.pop();
                    
                    let matrixPeek = new THREE.Matrix4().copy( matrixStack[matrixStack.length - 1] ).multiply( child.matrix );
                    matrixStack.push( matrixPeek );
                    parent = child;
                }
            } );

			modelMesh = meshList[0].clone();

			for (let i = 1; i < triangleMaterialMarkers.length; i++) {
				triangleMaterialMarkers[i] += triangleMaterialMarkers[i-1];
			}
			
            var geoList = [];
			for (let i = 0; i < meshList.length; i++) {
				geoList.push(meshList[i].geometry);
			}
			
            modelMesh.geometry = THREE.BufferGeometryUtils.mergeBufferGeometries(geoList);
            if (modelMesh.geometry.index)
                modelMesh.geometry = modelMesh.geometry.toNonIndexed();
				
			for (let i = 0; i < meshList.length; i++) {
				if (meshList[i].material.map != undefined)
					uniqueMaterialTextures.push(meshList[i].material.map);		
			}
			
			for (let i = 0; i < uniqueMaterialTextures.length; i++) {
				for (let j = i + 1; j < uniqueMaterialTextures.length; j++) {
					if (uniqueMaterialTextures[i].image.src == uniqueMaterialTextures[j].image.src) {
						uniqueMaterialTextures.splice(j, 1);
						j -= 1;
					}
				}	
			}
			
			for (let i = 0; i < meshList.length; i++) {
				if (meshList[i].material.map != undefined) {
					for (let j = 0; j < uniqueMaterialTextures.length; j++) {
						if (meshList[i].material.map.image.src == uniqueMaterialTextures[j].image.src) {
							pathTracingMaterialList[i].albedoTextureID = j;
						}
					}
				}				
			}

			// ********* different GLTF Model Settings **********

			// settings for Duck model
			//modelScale = 0.1;
			//modelPositionOffset.set(0, 20, -80);

			// settings for damagedHelmet model
			//modelScale = 10.0;
			//modelMesh.geometry.rotateY(Math.PI);
			//modelPositionOffset.set(0, 30, -50);

			// settings for scene model
			modelScale = 10.0;
			//modelMesh.geometry.rotateY(Math.PI);
			//modelPositionOffset.set(0, 4, -100);
			
			// now that the models have been loaded, we can init everything else
            init();
	
		});
		



		function init() {

			if ('ontouchstart' in window) {
				mouseControl = false;
				pixelRatio = 0.5;

				mobileJoystickControls = new MobileJoystickControls({
					//showJoystick: true,
					enableMultiTouch: true
				});
			}

			// if on mobile device, unpause the app because there is no ESC key and no mouse capture to do
			if (!mouseControl)
				isPaused = false;

			if (mouseControl) {

				window.addEventListener('wheel', onMouseWheel, false);

				document.body.addEventListener("click", function () {
					this.requestPointerLock = this.requestPointerLock || this.mozRequestPointerLock;
					this.requestPointerLock();
				}, false);

				window.addEventListener("click", function (event) {
					event.preventDefault();
				}, false);
				window.addEventListener("dblclick", function (event) {
					event.preventDefault();
				}, false);


				var pointerlockChange = function (event) {

					if (document.pointerLockElement === document.body ||
						document.mozPointerLockElement === document.body || document.webkitPointerLockElement === document.body) {

						isPaused = false;

					} else {

						isPaused = true;

					}

				};

				// Hook pointer lock state change events
				document.addEventListener('pointerlockchange', pointerlockChange, false);
				document.addEventListener('mozpointerlockchange', pointerlockChange, false);
				document.addEventListener('webkitpointerlockchange', pointerlockChange, false);

			}

			canvas = document.createElement( 'canvas' );
			context = canvas.getContext( 'webgl2' );
			
			renderer = new THREE.WebGLRenderer( { canvas: canvas, context: context } );
			renderer.autoClear = false;
			// 1 is full resolution, 0.5 is half, 0.25 is quarter, etc. (must be > than 0.0)
			renderer.setPixelRatio(pixelRatio);
			renderer.setSize( window.innerWidth, window.innerHeight );
			//required by WebGL 2.0 for rendering to FLOAT textures
			renderer.context.getExtension('EXT_color_buffer_float');

			container = document.getElementById('container');
			container.appendChild(renderer.domElement);

			stats = new Stats();
			stats.domElement.style.position = 'absolute';
			stats.domElement.style.top = '0px';
			stats.domElement.style.cursor = "default";
			stats.domElement.style.webkitUserSelect = "none";
			stats.domElement.style.MozUserSelect = "none";
			container.appendChild(stats.domElement);

			window.addEventListener('resize', onWindowResize, false);

			clock = new THREE.Clock();

			pathTracingScene = new THREE.Scene();
			screenTextureScene = new THREE.Scene();
			screenOutputScene = new THREE.Scene();

			// quadCamera is simply the camera to help render the full screen quad (2 triangles),
			// hence the name.  It is an Orthographic camera that sits facing the view plane, which serves as
			// the window into our 3d world. This camera will not move or rotate for the duration of the app.
			quadCamera = new THREE.OrthographicCamera(-1, 1, 1, -1, 0, 1);
			screenTextureScene.add(quadCamera);
			screenOutputScene.add(quadCamera);

			// worldCamera is the dynamic camera 3d object that will be positioned, oriented and 
			// constantly updated inside the 3d scene.  Its view will ultimately get passed back to the 
			// stationary quadCamera, which renders the scene to a fullscreen quad (made up of 2 large triangles).
			worldCamera = new THREE.PerspectiveCamera(72, 1, 1, 1000);
			pathTracingScene.add(worldCamera);

			controls = new FirstPersonCameraControls(worldCamera);

			cameraControlsObject = controls.getObject();
			cameraControlsYawObject = controls.getYawObject();
			cameraControlsPitchObject = controls.getPitchObject();

			pathTracingScene.add(cameraControlsObject);

			// for flyCam
			cameraControlsObject.position.set(30, 40, 50);

			// look slightly downward
			cameraControlsPitchObject.rotation.x = -0.2;

			oldYawRotation = cameraControlsYawObject.rotation.y;
			oldPitchRotation = cameraControlsPitchObject.rotation.x;

			// now that we moved and rotated the camera, the following line force-updates the camera's matrix,
			//  and prevents rendering the very first frame in the old default camera position/orientation
			cameraControlsObject.updateMatrixWorld(true);

			pathTracingRenderTarget = new THREE.WebGLRenderTarget((window.innerWidth * pixelRatio), (window.innerHeight *
				pixelRatio), {
				minFilter: THREE.NearestFilter,
				magFilter: THREE.NearestFilter,
				format: THREE.RGBAFormat,
				type: THREE.FloatType,
				depthBuffer: false,
				stencilBuffer: false
			});
			pathTracingRenderTarget.texture.generateMipmaps = false;

			screenTextureRenderTarget = new THREE.WebGLRenderTarget((window.innerWidth * pixelRatio), (window.innerHeight *
				pixelRatio), {
				minFilter: THREE.NearestFilter,
				magFilter: THREE.NearestFilter,
				format: THREE.RGBAFormat,
				type: THREE.FloatType,
				depthBuffer: false,
				stencilBuffer: false
			});
			screenTextureRenderTarget.texture.generateMipmaps = false;


			total_number_of_triangles = modelMesh.geometry.attributes.position.array.length / 9;
			console.log("Triangle count:" + total_number_of_triangles);

			totalWork = new Uint32Array(total_number_of_triangles);

			triangle_array = new Float32Array(2048 * 2048 * 4);
			// 2048 = width of texture, 2048 = height of texture, 4 = r,g,b, and a components
			
			aabb_array = new Float32Array(2048 * 2048 * 4);
			// 2048 = width of texture, 2048 = height of texture, 4 = r,g,b, and a components
			
			
			

			// settings for monkey model
			//modelScale = 10.0;
			//modelPositionOffset.set(0, 30, -40);

			// settings for UtahTeapot model
			//modelScale = 1.0;
			//modelPositionOffset.set(10, 26, -30);

			

			// settings for f16 model
			//modelScale = 16.0;
			//modelPositionOffset.set(0, 30, -40);

			// settings for stanford-bunny model
			//modelScale = 0.04;
			//modelPositionOffset.set(0, 27.5, -40);


			// settings for modern Tron cycle model
			//modelScale = 25.0;
			//modelMesh.geometry.rotateX(-Math.PI * 0.5);
			//modelMesh.geometry.lookAt(new THREE.Vector3(-1000, -500, -500));
			//modelPositionOffset.set(-70, 0, -80);

			// settings for stanford-dragon model
			//modelScale = 3.0;
			//modelPositionOffset.set(0, 18, -40);

			// settings for stanford-buddha model
			//modelScale = 3.0;
			//modelPositionOffset.set(0, 18, -40);

			// settings for sponza model
			//modelScale = 0.1;
			//modelPositionOffset.set(0, 0, -100);

			// settings for stanford-angelLucy model (might take 10 seconds to compile)
			//modelScale = 0.05;
			//modelMesh.geometry.lookAt(new THREE.Vector3(1000, 0, 0));
			//modelPositionOffset.set(0, 17.3, -40);


			
			var triangle_b_box_min = new THREE.Vector3();
			var triangle_b_box_max = new THREE.Vector3();
			var triangle_b_box_centroid = new THREE.Vector3();
			

			var vpa = new Float32Array(modelMesh.geometry.attributes.position.array);
            if (modelMesh.geometry.attributes.normal === undefined)
                modelMesh.geometry.computeVertexNormals();
			var vna = new Float32Array(modelMesh.geometry.attributes.normal.array);

			
			var modelHasUVs = false;
			if (modelMesh.geometry.attributes.uv !== undefined) {
				var vta = new Float32Array(modelMesh.geometry.attributes.uv.array);
				modelHasUVs = true;
			}
				
			var materialNumber = 0;

			for (let i = 0; i < total_number_of_triangles; i++) {
			
				triangle_b_box_min.set(Infinity, Infinity, Infinity);
				triangle_b_box_max.set(-Infinity, -Infinity, -Infinity);

				for (let j = 0; j < pathTracingMaterialList.length; j++) {
					if (i < triangleMaterialMarkers[j]) {
						materialNumber = j;
						break;
					}
				}

				// record vertex texture coordinates (UVs)
				if (modelHasUVs) {
					vt0.set( vta[6 * i + 0], vta[6 * i + 1] );
					vt1.set( vta[6 * i + 2], vta[6 * i + 3] );
					vt2.set( vta[6 * i + 4], vta[6 * i + 5] );
				}
				else {
					vt0.set( -1, -1 );
					vt1.set( -1, -1 );
					vt2.set( -1, -1 );
				}
				
				// record vertex normals
				vn0.set( vna[9 * i + 0], vna[9 * i + 1], vna[9 * i + 2] ).normalize();
				vn1.set( vna[9 * i + 3], vna[9 * i + 4], vna[9 * i + 5] ).normalize();
				vn2.set( vna[9 * i + 6], vna[9 * i + 7], vna[9 * i + 8] ).normalize();
				
				// record vertex positions
				vp0.set( vpa[9 * i + 0], vpa[9 * i + 1], vpa[9 * i + 2] );
				vp1.set( vpa[9 * i + 3], vpa[9 * i + 4], vpa[9 * i + 5] );
				vp2.set( vpa[9 * i + 6], vpa[9 * i + 7], vpa[9 * i + 8] );

				vp0.multiplyScalar(modelScale);
				vp1.multiplyScalar(modelScale);
				vp2.multiplyScalar(modelScale);

				vp0.add(modelPositionOffset);
				vp1.add(modelPositionOffset);
				vp2.add(modelPositionOffset);

				//slot 0
				triangle_array[32 * i +  0] = vp0.x; // r or x
				triangle_array[32 * i +  1] = vp0.y; // g or y 
				triangle_array[32 * i +  2] = vp0.z; // b or z
				triangle_array[32 * i +  3] = vp1.x; // a or w

				//slot 1
				triangle_array[32 * i +  4] = vp1.y; // r or x
				triangle_array[32 * i +  5] = vp1.z; // g or y
				triangle_array[32 * i +  6] = vp2.x; // b or z
				triangle_array[32 * i +  7] = vp2.y; // a or w

				//slot 2
				triangle_array[32 * i +  8] = vp2.z; // r or x
				triangle_array[32 * i +  9] = vn0.x; // g or y
				triangle_array[32 * i + 10] = vn0.y; // b or z
				triangle_array[32 * i + 11] = vn0.z; // a or w

				//slot 3
				triangle_array[32 * i + 12] = vn1.x; // r or x
				triangle_array[32 * i + 13] = vn1.y; // g or y
				triangle_array[32 * i + 14] = vn1.z; // b or z
				triangle_array[32 * i + 15] = vn2.x; // a or w

				//slot 4
				triangle_array[32 * i + 16] = vn2.y; // r or x
				triangle_array[32 * i + 17] = vn2.z; // g or y
				triangle_array[32 * i + 18] = vt0.x; // b or z
				triangle_array[32 * i + 19] = vt0.y; // a or w

				//slot 5
				triangle_array[32 * i + 20] = vt1.x; // r or x
				triangle_array[32 * i + 21] = vt1.y; // g or y
				triangle_array[32 * i + 22] = vt2.x; // b or z
				triangle_array[32 * i + 23] = vt2.y; // a or w

				// the remaining slots are used for PBR material properties

				//slot 6
				triangle_array[32 * i + 24] = pathTracingMaterialList[materialNumber].type; // r or x 
				triangle_array[32 * i + 25] = pathTracingMaterialList[materialNumber].color.r; // g or y
				triangle_array[32 * i + 26] = pathTracingMaterialList[materialNumber].color.g; // b or z
				triangle_array[32 * i + 27] = pathTracingMaterialList[materialNumber].color.b; // a or w

				//slot 7
				triangle_array[32 * i + 28] = pathTracingMaterialList[materialNumber].albedoTextureID; // r or x
				triangle_array[32 * i + 29] = 0; // g or y
				triangle_array[32 * i + 30] = 0; // b or z
				triangle_array[32 * i + 31] = 0; // a or w

				triangle_b_box_min.copy(triangle_b_box_min.min(vp0));
				triangle_b_box_max.copy(triangle_b_box_max.max(vp0));
				triangle_b_box_min.copy(triangle_b_box_min.min(vp1));
				triangle_b_box_max.copy(triangle_b_box_max.max(vp1));
				triangle_b_box_min.copy(triangle_b_box_min.min(vp2));
				triangle_b_box_max.copy(triangle_b_box_max.max(vp2));

				triangle_b_box_centroid.set((triangle_b_box_min.x + triangle_b_box_max.x) * 0.5,
					(triangle_b_box_min.y + triangle_b_box_max.y) * 0.5,
					(triangle_b_box_min.z + triangle_b_box_max.z) * 0.5);

				aabb_array[9 * i + 0] = triangle_b_box_min.x;
				aabb_array[9 * i + 1] = triangle_b_box_min.y;
				aabb_array[9 * i + 2] = triangle_b_box_min.z;
				aabb_array[9 * i + 3] = triangle_b_box_max.x;
				aabb_array[9 * i + 4] = triangle_b_box_max.y;
				aabb_array[9 * i + 5] = triangle_b_box_max.z;
				aabb_array[9 * i + 6] = triangle_b_box_centroid.x;
				aabb_array[9 * i + 7] = triangle_b_box_centroid.y;
				aabb_array[9 * i + 8] = triangle_b_box_centroid.z;

				totalWork[i] = i;
			}


			// Build the BVH acceleration structure, which places a bounding box ('root' of the tree) around all of the 
			// triangles of the entire mesh, then subdivides each box into 2 smaller boxes.  It continues until it reaches 1 triangle,
			// which it then designates as a 'leaf'
			BVH_Build_Iterative(totalWork);
			//console.log(buildnodes);

			// Copy the buildnodes array into the aabb_array
			for (let n = 0; n < buildnodes.length; n++) {

				// slot 0
				aabb_array[8 * n + 0] = buildnodes[n].idLeftChild;  // r or x component
				aabb_array[8 * n + 1] = buildnodes[n].minCorner.x;  // g or y component
				aabb_array[8 * n + 2] = buildnodes[n].minCorner.y;  // b or z component
				aabb_array[8 * n + 3] = buildnodes[n].minCorner.z;  // a or w component

				// slot 1
				aabb_array[8 * n + 4] = buildnodes[n].idRightChild; // r or x component
				aabb_array[8 * n + 5] = buildnodes[n].maxCorner.x;  // g or y component
				aabb_array[8 * n + 6] = buildnodes[n].maxCorner.y;  // b or z component
				aabb_array[8 * n + 7] = buildnodes[n].maxCorner.z;  // a or w component

			}

			triangleDataTexture = new THREE.DataTexture(triangle_array,
				2048,
				2048,
				THREE.RGBAFormat,
				THREE.FloatType,
				THREE.Texture.DEFAULT_MAPPING,
				THREE.ClampToEdgeWrapping,
				THREE.ClampToEdgeWrapping,
				THREE.NearestFilter,
				THREE.NearestFilter,
				1,
				THREE.LinearEncoding);

			triangleDataTexture.flipY = false;
			triangleDataTexture.generateMipmaps = false;
			triangleDataTexture.needsUpdate = true;

			aabbDataTexture = new THREE.DataTexture(aabb_array,
				2048,
				2048,
				THREE.RGBAFormat,
				THREE.FloatType,
				THREE.Texture.DEFAULT_MAPPING,
				THREE.ClampToEdgeWrapping,
				THREE.ClampToEdgeWrapping,
				THREE.NearestFilter,
				THREE.NearestFilter,
				1,
				THREE.LinearEncoding);

			aabbDataTexture.flipY = false;
			aabbDataTexture.generateMipmaps = false;
			aabbDataTexture.needsUpdate = true;

			/*
			albedoTexture = new THREE.TextureLoader().load( 'textures/uvGrid.jpg' );
			albedoTexture.wrapS = THREE.RepeatWrapping;
			albedoTexture.wrapT = THREE.RepeatWrapping;
			*/

			pathTracingGeometry = new THREE.PlaneBufferGeometry(2, 2);

			pathTracingUniforms = {

				tPreviousTexture: { type: "t", value: screenTextureRenderTarget.texture },
				tTriangleTexture: { type: "t", value: triangleDataTexture },
				tAABBTexture: { type: "t", value: aabbDataTexture },
				tAlbedoTextures: { type: "t", value: uniqueMaterialTextures },

				uCameraIsMoving: { type: "b1", value: false },
				uCameraJustStartedMoving: { type: "b1", value: false },

				uTime: { type: "f", value: 0.0 },
				uSampleCounter: { type: "f", value: 1.0 },
				uFrameCounter: { type: "f", value: 1.0 },
				uULen: { type: "f", value: 1.0 },
				uVLen: { type: "f", value: 1.0 },
				uApertureSize: { type: "f", value: 0.0 },
				uFocusDistance: { type: "f", value: 100.0 },

				uResolution: { type: "v2", value: new THREE.Vector2() },

				uRandomVector: { type: "v3", value: new THREE.Vector3() },

				uCameraMatrix: {type: "m4", value: new THREE.Matrix4() },

			};

			pathTracingDefines = {
				//N_ALBEDO_MAPS: uniqueMaterialTextures.length
			};

			pathTracingMaterial = new THREE.ShaderMaterial({
				uniforms: pathTracingUniforms,
				defines: pathTracingDefines,
				vertexShader: document.getElementById('pathTracingVertexShader').textContent,
				fragmentShader: document.getElementById('pathTracingFragmentShader').textContent,
				depthTest: false,
				depthWrite: false
			});

			pathTracingMesh = new THREE.Mesh(pathTracingGeometry, pathTracingMaterial);
			pathTracingScene.add(pathTracingMesh);

			screenTextureGeometry = new THREE.PlaneBufferGeometry(2, 2);

			screenTextureMaterial = new THREE.ShaderMaterial({
				uniforms: screenTextureShader.uniforms,
				vertexShader: screenTextureShader.vertexShader,
				fragmentShader: screenTextureShader.fragmentShader,
				depthWrite: false,
				depthTest: false
			});

			screenTextureMaterial.uniforms.tTexture0.value = pathTracingRenderTarget.texture;

			screenTextureMesh = new THREE.Mesh(screenTextureGeometry, screenTextureMaterial);
			screenTextureScene.add(screenTextureMesh);



			screenOutputGeometry = new THREE.PlaneBufferGeometry(2, 2);

			screenOutputMaterial = new THREE.ShaderMaterial({
				uniforms: screenOutputShader.uniforms,
				vertexShader: screenOutputShader.vertexShader,
				fragmentShader: screenOutputShader.fragmentShader,
				depthWrite: false,
				depthTest: false
			});

			screenOutputMaterial.uniforms.tTexture0.value = pathTracingRenderTarget.texture;

			screenOutputMesh = new THREE.Mesh(screenOutputGeometry, screenOutputMaterial);
			screenOutputScene.add(screenOutputMesh);


			// the following keeps the large scene ShaderMaterial quad right in front 
			//   of the camera at all times. This is necessary because without it, the scene 
			//   quad will fall out of view and get clipped when the camera rotates past 180 degrees.
			worldCamera.add(pathTracingMesh);


			/*
			// Fullscreen API
			document.addEventListener("click", function() {
				
				if ( !document.fullscreenElement && !document.mozFullScreenElement && !document.webkitFullscreenElement ) {

					if (document.documentElement.requestFullscreen) {
						document.documentElement.requestFullscreen();
						
					} else if (document.documentElement.mozRequestFullScreen) {
						document.documentElement.mozRequestFullScreen();
					
					} else if (document.documentElement.webkitRequestFullscreen) {
						document.documentElement.webkitRequestFullscreen();
					
					}

				}
			});
			*/

			// onWindowResize() must be at the end of the init() function
			onWindowResize();

			// everything is set up, now we can start animating
			animate();

		} // end function init()



		function onWindowResize(event) {

			SCREEN_WIDTH = window.innerWidth;
			SCREEN_HEIGHT = window.innerHeight;

			renderer.setPixelRatio(pixelRatio);
			renderer.setSize(SCREEN_WIDTH, SCREEN_HEIGHT);

			fontAspect = (SCREEN_WIDTH / 175) * (SCREEN_HEIGHT / 200);
			if (fontAspect > 25) fontAspect = 25;
			if (fontAspect < 4) fontAspect = 4;
			fontAspect *= 2;

			pathTracingUniforms.uResolution.value.x = renderer.context.drawingBufferWidth;
			pathTracingUniforms.uResolution.value.y = renderer.context.drawingBufferHeight;

			pathTracingRenderTarget.setSize(renderer.context.drawingBufferWidth, renderer.context.drawingBufferHeight);
			screenTextureRenderTarget.setSize(renderer.context.drawingBufferWidth, renderer.context.drawingBufferHeight);

			worldCamera.aspect = renderer.domElement.clientWidth / renderer.domElement.clientHeight;
			worldCamera.updateProjectionMatrix();

			// the following scales all scene objects by the worldCamera's field of view,
			// taking into account the screen aspect ratio and multiplying the uniform uULen,
			// the x-coordinate, by this ratio
			fovScale = worldCamera.fov * 0.5 * (Math.PI / 180.0);
			pathTracingUniforms.uVLen.value = Math.tan(fovScale);
			pathTracingUniforms.uULen.value = pathTracingUniforms.uVLen.value * worldCamera.aspect;

			if (!mouseControl) {

				button1Element.style.display = "";
				button2Element.style.display = "";
				button3Element.style.display = "";
				button4Element.style.display = "";
				button5Element.style.display = "";
				button6Element.style.display = "";
				// check if mobile device is in portrait or landscape mode and position buttons accordingly
				if (SCREEN_WIDTH < SCREEN_HEIGHT) {

					button1Element.style.right = 36 + "%";
					button2Element.style.right = 2 + "%";
					button3Element.style.right = 16 + "%";
					button4Element.style.right = 16 + "%";
					button5Element.style.right = 3 + "%";
					button6Element.style.right = 3 + "%";

					button1Element.style.bottom = 5 + "%";
					button2Element.style.bottom = 5 + "%";
					button3Element.style.bottom = 13 + "%";
					button4Element.style.bottom = 2 + "%";
					button5Element.style.bottom = 25 + "%";
					button6Element.style.bottom = 18 + "%";

				} else {

					button1Element.style.right = 22 + "%";
					button2Element.style.right = 3 + "%";
					button3Element.style.right = 11 + "%";
					button4Element.style.right = 11 + "%";
					button5Element.style.right = 3 + "%";
					button6Element.style.right = 3 + "%";

					button1Element.style.bottom = 10 + "%";
					button2Element.style.bottom = 10 + "%";
					button3Element.style.bottom = 26 + "%";
					button4Element.style.bottom = 4 + "%";
					button5Element.style.bottom = 48 + "%";
					button6Element.style.bottom = 34 + "%";

				}

			} // end if ( !mouseControl ) {

		} // end function onWindowResize( event )



		function animate() {

			requestAnimationFrame(animate);

			frameTime = clock.getDelta();

			//elapsedTime = clock.getElapsedTime() % 1000;

			// reset flags
			cameraIsMoving = false;
			cameraJustStartedMoving = false;

			// check user controls
			if (mouseControl) {
				// movement detected
				if (oldYawRotation != cameraControlsYawObject.rotation.y ||
					oldPitchRotation != cameraControlsPitchObject.rotation.x) {

					cameraIsMoving = true;
				}

				// save state for next frame
				oldYawRotation = cameraControlsYawObject.rotation.y;
				oldPitchRotation = cameraControlsPitchObject.rotation.x;

			} // end if (mouseControl)

			// if not playing on desktop, get input from the mobileJoystickControls
			if (!mouseControl) {

				newDeltaX = joystickDeltaX;

				if (newDeltaX) {

					mobileControlsMoveX = oldDeltaX - newDeltaX;
					// smooth out jerkiness if camera was sitting still 
					if (stillFlagX) {
						mobileControlsMoveX *= 0.1;
						stillFlagX = false;
					}
					// mobileJoystick X movement (left and right) affects camera rotation around the Y axis	
					cameraControlsYawObject.rotation.y += (mobileControlsMoveX) * 0.01;
				}

				newDeltaY = joystickDeltaY;

				if (newDeltaY) {

					mobileControlsMoveY = oldDeltaY - newDeltaY;
					// smooth out jerkiness if camera was sitting still
					if (stillFlagY) {
						mobileControlsMoveY *= 0.1;
						stillFlagY = false;
					}
					// mobileJoystick Y movement (up and down) affects camera rotation around the X axis	
					cameraControlsPitchObject.rotation.x += (mobileControlsMoveY) * 0.01;
				}

				// clamp the camera's vertical movement (around the x-axis) to the scene's 'ceiling' and 'floor',
				// so you can't accidentally flip the camera upside down
				cameraControlsPitchObject.rotation.x = Math.max(-PI_2, Math.min(PI_2, cameraControlsPitchObject.rotation.x));

				// save state for next frame
				oldDeltaX = newDeltaX;
				oldDeltaY = newDeltaY;

				// movement detected
				if (newDeltaX || newDeltaY) {

					cameraIsMoving = true;
				} else {
					stillFlagX = true;
					stillFlagY = true;
				}

				newPinchWidthX = pinchWidthX;
				newPinchWidthY = pinchWidthY;
				pinchDeltaX = newPinchWidthX - oldPinchWidthX;
				pinchDeltaY = newPinchWidthY - oldPinchWidthY;

				if (Math.abs(pinchDeltaX) > Math.abs(pinchDeltaY)) {
					if (pinchDeltaX < -3) increaseFOV = true;
					if (pinchDeltaX > 3) decreaseFOV = true;
				}

				if (Math.abs(pinchDeltaY) >= Math.abs(pinchDeltaX)) {
					if (pinchDeltaY > 1) increaseAperture = true;
					if (pinchDeltaY < -1) decreaseAperture = true;
				}

				// save state for next frame
				oldPinchWidthX = newPinchWidthX;
				oldPinchWidthY = newPinchWidthY;

			} // end if ( !mouseControl )

			// this gives us a vector in the direction that the camera is pointing,
			// which will be useful for moving the camera 'forward' and shooting projectiles in that direction
			controls.getDirection(cameraDirectionVector);
			cameraDirectionVector.normalize();
			controls.getUpVector(cameraUpVector);
			controls.getRightVector(cameraRightVector);

			// the following gives us a rotation quaternion (4D vector), which will be useful for 
			// rotating scene objects to match the camera's rotation
			worldCamera.getWorldQuaternion(cameraWorldQuaternion);

			// allow flying camera
			if ((keyboard.pressed('W') || button3Pressed) && !(keyboard.pressed('S') || button4Pressed)) {

				cameraControlsObject.position.add(cameraDirectionVector.multiplyScalar(camFlightSpeed * frameTime));
				cameraIsMoving = true;
			}
			if ((keyboard.pressed('S') || button4Pressed) && !(keyboard.pressed('W') || button3Pressed)) {

				cameraControlsObject.position.sub(cameraDirectionVector.multiplyScalar(camFlightSpeed * frameTime));
				cameraIsMoving = true;
			}
			if ((keyboard.pressed('A') || button1Pressed) && !(keyboard.pressed('D') || button2Pressed)) {

				cameraControlsObject.position.sub(cameraRightVector.multiplyScalar(camFlightSpeed * frameTime));
				cameraIsMoving = true;
			}
			if ((keyboard.pressed('D') || button2Pressed) && !(keyboard.pressed('A') || button1Pressed)) {

				cameraControlsObject.position.add(cameraRightVector.multiplyScalar(camFlightSpeed * frameTime));
				cameraIsMoving = true;
			}
			if (keyboard.pressed('E') && !keyboard.pressed('Q')) {

				cameraControlsObject.position.add(cameraUpVector.multiplyScalar(camFlightSpeed * frameTime));
				cameraIsMoving = true;
			}
			if (keyboard.pressed('Q') && !keyboard.pressed('E')) {

				cameraControlsObject.position.sub(cameraUpVector.multiplyScalar(camFlightSpeed * frameTime));
				cameraIsMoving = true;
			}
			if ((keyboard.pressed('up') || button5Pressed) && !(keyboard.pressed('down') || button6Pressed)) {

				increaseFocusDist = true;
			}
			if ((keyboard.pressed('down') || button6Pressed) && !(keyboard.pressed('up') || button5Pressed)) {

				decreaseFocusDist = true;
			}
			if (keyboard.pressed('right') && !keyboard.pressed('left')) {

				increaseAperture = true;
			}
			if (keyboard.pressed('left') && !keyboard.pressed('right')) {

				decreaseAperture = true;
			}

			if (increaseFOV) {
				worldCamera.fov++;
				if (worldCamera.fov > 150)
					worldCamera.fov = 150;
				fovScale = worldCamera.fov * 0.5 * (Math.PI / 180.0);
				pathTracingUniforms.uVLen.value = Math.tan(fovScale);
				pathTracingUniforms.uULen.value = pathTracingUniforms.uVLen.value * worldCamera.aspect;

				cameraIsMoving = true;
				increaseFOV = false;
			}
			if (decreaseFOV) {
				worldCamera.fov--;
				if (worldCamera.fov < 1)
					worldCamera.fov = 1;
				fovScale = worldCamera.fov * 0.5 * (Math.PI / 180.0);
				pathTracingUniforms.uVLen.value = Math.tan(fovScale);
				pathTracingUniforms.uULen.value = pathTracingUniforms.uVLen.value * worldCamera.aspect;

				cameraIsMoving = true;
				decreaseFOV = false;
			}

			if (increaseFocusDist) {
				focusDistance += 1;
				pathTracingUniforms.uFocusDistance.value = focusDistance;
				cameraIsMoving = true;
				increaseFocusDist = false;
			}
			if (decreaseFocusDist) {
				focusDistance -= 1;
				if (focusDistance < 1)
					focusDistance = 1;
				pathTracingUniforms.uFocusDistance.value = focusDistance;
				cameraIsMoving = true;
				decreaseFocusDist = false;
			}

			if (increaseAperture) {
				apertureSize += 0.1;
				if (apertureSize > 20.0)
					apertureSize = 20.0;
				pathTracingUniforms.uApertureSize.value = apertureSize;
				cameraIsMoving = true;
				increaseAperture = false;
			}
			if (decreaseAperture) {
				apertureSize -= 0.1;
				if (apertureSize < 0.0)
					apertureSize = 0.0;
				pathTracingUniforms.uApertureSize.value = apertureSize;
				cameraIsMoving = true;
				decreaseAperture = false;
			}


			if ( cameraIsMoving ) {
					
				sampleCounter = 1.0;
				frameCounter  += 1.0;
					
				if ( !cameraRecentlyMoving ) {
					cameraJustStartedMoving = true;
					cameraRecentlyMoving = true;
				}
					
			}
				
			if ( !cameraIsMoving ) {

				sampleCounter += 1.0;
				frameCounter  += 1.0;
				if (cameraRecentlyMoving)
					frameCounter = 1.0;
				
				cameraRecentlyMoving = false;
				
			}


			pathTracingUniforms.uCameraIsMoving.value = cameraIsMoving;
			pathTracingUniforms.uCameraJustStartedMoving.value = cameraJustStartedMoving;
			pathTracingUniforms.uSampleCounter.value = sampleCounter;
			pathTracingUniforms.uFrameCounter.value = frameCounter;
			pathTracingUniforms.uRandomVector.value = randomVector.set(Math.random(), Math.random(), Math.random());
			// CAMERA
			cameraControlsObject.updateMatrixWorld(true);
			pathTracingUniforms.uCameraMatrix.value.copy(worldCamera.matrixWorld);
			screenOutputMaterial.uniforms.uOneOverSampleCounter.value = 1.0 / sampleCounter;

			cameraInfoElement.innerHTML = "FOV: " + worldCamera.fov + " / Aperture: " + apertureSize.toFixed(2) +
				" / FocusDistance: " + focusDistance + "<br>" + "Samples: " + sampleCounter;


			// RENDERING in 3 steps

			// STEP 1
			// Perform PathTracing and Render(save) into pathTracingRenderTarget
			// Read previous screenTextureRenderTarget to use as a new starting point to blend with
			renderer.render(pathTracingScene, worldCamera, pathTracingRenderTarget);

			// STEP 2
			// Render(copy) the final pathTracingScene output(above) into screenTextureRenderTarget
			// This will be used as a new starting point for Step 1 above
			renderer.render(screenTextureScene, quadCamera, screenTextureRenderTarget);

			// STEP 3
			// Render full screen quad with generated pathTracingRenderTarget in STEP 1 above.
			// After the image is gamma corrected, it will be shown on the screen as the final accumulated output
			renderer.render(screenOutputScene, quadCamera);


			stats.update();


		} // end function animate()
	</script>

</body>

</html>
