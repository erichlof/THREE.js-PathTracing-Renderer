<!DOCTYPE html>
<html lang="en">
	<head>
		<title>three.js PathTracing Renderer - Planet Rendering (preview - WIP)</title>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, user-scalable=no, initial-scale=1">
		<style>

			html, body {
				width: 100%;
				height: 100%;
				font-family: Monospace;
				background-color: #000;
				color: #000;
				margin: 0px;
				overflow: hidden;
				touch-action: none;
				cursor: default;
			}
			
			#info {
				position: fixed;
				top: 5px;
				width: 100%;
				text-align: center;
				color: #ffffff;
				cursor: default;
				user-select: none;
			}

			#cameraInfo {
				position: fixed;
				left: 3%;
				bottom: 2%;
				font-family: Arial;
				color: #ffffff;
				cursor: default;
				user-select: none;
			}

			.toggleButton {
				position:fixed;
				background-color: gray;
				border: none;
				color: white;
				top: 5px;
				right: 5px;
				padding: 10px 20px;
				text-align: center;
				text-decoration: none;
				font-size: 14px;
				margin: 4px 2px;
				cursor: pointer;
				user-select: none;
				z-index: 11;
			}
			#timePauseButton {
				top: 50px;
			}		
			
		</style>
	</head>
	<body>

		<div id="container"> </div>
		
		<div id="info">three.js PathTracing Renderer - Planet Rendering (preview - WIP)</div>
		<button id="cameraPosButton" class="toggleButton" onclick="toggleCameraPos()">Teleport to Surface</button>
		<button id="timePauseButton" class="toggleButton" onclick="toggleTimePause()">Pause Time</button>
		<div id="cameraInfo"> </div>


		<script src="js/three.min.js"> </script>
		<script src="js/pathTracingCommon.js"> </script>
		<script src="js/threex.keyboardstate.js"> </script>
		<!-- <script src="js/FirstPersonCameraControls.js"> </script> -->
		<script>
		// this demo's camera code requires a slight change to yawObject.rotation, as seen below
		var FirstPersonCameraControls = function ( camera ) {

			camera.rotation.set( 0, 0, 0 );
			var pitchObject = new THREE.Object3D();
			pitchObject.add( camera );
			var yawObject = new THREE.Object3D();
			yawObject.add( pitchObject );
			var movementX = 0;
			var movementY = 0;			
			var onMouseMove = function ( event ) {
				if (isPaused)
					return;
				movementX = event.movementX || event.mozMovementX || 0;
				movementY = event.movementY || event.mozMovementY || 0;
				/// yawObject.rotation.y -= movementX * 0.002;
				yawObject.rotateOnWorldAxis(yawObject.up, -movementX * 0.002);
				pitchObject.rotation.x -= movementY * 0.002;
				// clamp the camera's vertical movement (around the x-axis) to the scene's 'ceiling' and 'floor'
				pitchObject.rotation.x = Math.max( - PI_2, Math.min( PI_2, pitchObject.rotation.x ) );			
			};
			document.addEventListener( 'mousemove', onMouseMove, false );
			this.getObject = function () {
				return yawObject;
			};
			this.getYawObject = function () {
				return yawObject;
			};
			this.getPitchObject = function () {
				return pitchObject;
			};
			this.getDirection = function() {
				var te = pitchObject.matrixWorld.elements;
				return function( v ) {			
					v.set( te[ 8 ], te[ 9 ], te[ 10 ] ).negate();			
					return v;
				};
			}();
			this.getUpVector = function() {
				var te = pitchObject.matrixWorld.elements;
				return function( v ) {		
					v.set( te[ 4 ], te[ 5 ], te[ 6 ] );		
					return v;
				};
			}();
			this.getRightVector = function() {
				var te = pitchObject.matrixWorld.elements;
				return function( v ) {			
					v.set( te[ 0 ], te[ 1 ], te[ 2 ] );			
					return v;
				};
			}();
		};
		</script>

		<script src="js/MobileJoystickControls.js"> </script>
		<script src="js/stats.min.js"> </script>
		
		
		<script id="pathTracingVertexShader" type="x-shader/x-vertex">
#version 300 es

precision highp float;
precision highp int;

out vec2 vUv;

void main()
{
	vUv = uv;
	gl_Position = vec4( position, 1.0 );
}

		</script>
		
		
		
		<script id="pathTracingFragmentShader" type="x-shader/x-fragment">
#version 300 es

precision highp float;
precision highp int;
precision highp sampler2D;

uniform sampler2D t_PerlinNoise;
uniform vec3 uSunDirection;
uniform vec3 uCameraFrameForward;
uniform vec3 uCameraFrameRight;
uniform vec3 uCameraFrameUp;
uniform float uCameraUnderWater;
uniform float uSunAngle;
uniform bool uCameraWithinAtmosphere;

#include <pathtracing_uniforms_and_defines>

#define N_SPHERES 2

//-----------------------------------------------------------------------

struct Ray { vec3 origin; vec3 direction; };
struct Sphere { float radius; vec3 position; vec3 emission; vec3 color; int type; };
struct Intersection { vec3 normal; vec3 emission; vec3 color; vec2 uv; int type; };

Sphere spheres[N_SPHERES];

#include <pathtracing_random_functions>

#include <pathtracing_calc_fresnel_reflectance>

#include <pathtracing_sphere_intersect>

#include <pathtracing_plane_intersect>

#define EARTH_RADIUS      6360.0 // in Km
#define ATMOSPHERE_RADIUS 6420.0 // in Km

vec3 hash33(vec3 p)
{
	p = fract(p * vec3(443.8975,397.2973, 491.1871));
    	p += dot(p.zxy, p.yxz+19.27);
    	return fract(vec3(p.x * p.y, p.z*p.x, p.y*p.z));
}

vec3 stars(in vec3 p)
{
	vec3 c = vec3(0);
	float res = uResolution.x;
	
	for (float i = 0.0; i < 4.0; i++)
	{
		vec3 q = fract(p*(.15*res))-0.5;
		vec3 id = floor(p*(.15*res));
		vec2 rn = hash33(id).xy;
		float c2 = 1.-smoothstep(0.,.6,length(q));
		c2 *= step(rn.x,.0005+i*i*0.001);
		c += c2*(mix(vec3(1.0,0.49,0.1),vec3(0.75,0.9,1.),clamp(rn.y,0.0,1.0))*0.1+0.9);
		p *= 1.3;
	}
	return vec3(pow(max(0.0,c.r), 5.0), pow(max(0.0,c.g), 7.0), pow(max(0.0,c.b), 6.5));
}

/*
float starRand(vec3 v)
{
	return fract(sin(dot(v ,vec3(12.9898,78.233,.0235))) * 43758.5453);
}
*/

//----------------------------------------------------------------------------------------
bool PlanetSphereIntersect( Ray ray, float rad, vec3 pos, inout float t0, inout float t1 )
//----------------------------------------------------------------------------------------
{
	vec3 L = ray.origin - pos;
	float a = dot( ray.direction, ray.direction );
	float b = 2.0 * dot( ray.direction, L );
	float c = dot( L, L ) - (rad * rad);

	if (!solveQuadratic( a, b, c, t0, t1))
		return false;
	
	float temp;
	if (t0 > t1)
	{
		temp = t0;
		t0 = t1;
		t1 = temp;
	}
	return true;
}

vec3 computeIncidentLight(Ray r, float tmin, float tmax)
{ 
	vec3 betaR = vec3(3.8e-3, 13.5e-3, 33.1e-3); 
	vec3 betaM = vec3(21e-3);  
	float Hr = 7.994;
	float Hm = 1.200;
	float t0, t1; 
	if (!PlanetSphereIntersect(r, ATMOSPHERE_RADIUS, vec3(0), t0, t1) || t1 < 0.0) return vec3(0); 
	if (t0 > tmin && t0 > 0.0) tmin = t0; 
	if (t1 < tmax) tmax = t1; 
	int numSamples = 16; 
	int numSamplesLight = 8; 
	float segmentLength = (tmax - tmin) / float(numSamples); 
	float tCurrent = tmin; 
	vec3 sumR = vec3(0); // rayleigh contribution
	vec3 sumM = vec3(0); // mie contribution 
	float opticalDepthR = 0.0;
	float opticalDepthM = 0.0; 
	float mu = dot(r.direction, uSunDirection); // mu in the paper which is the cosine of the angle between the sun direction and the ray direction 
	float phaseR = 3.0 / (16.0 * PI) * (1.0 + mu * mu); 
	float g = 0.76; 
	float phaseM = 3.0 / (8.0 * PI) * ((1.0 - g * g) * (1.0 + mu * mu)) / ((2.0 + g * g) * pow(max(0.0, 1.0 + g * g - 2.0 * g * mu), 1.5)); 
    	for (int i = 0; i < 16; ++i)
	{ 
		vec3 samplePosition = r.origin + (tCurrent + segmentLength * 0.5) * r.direction; 
		float height = length(samplePosition) - EARTH_RADIUS; 
		// compute optical depth for light
		float hr = exp(-height / Hr) * segmentLength; 
		float hm = exp(-height / Hm) * segmentLength; 
		opticalDepthR += hr; 
		opticalDepthM += hm; 
		// light optical depth
		float t0Light, t1Light; 
		PlanetSphereIntersect(Ray(samplePosition, uSunDirection), ATMOSPHERE_RADIUS, vec3(0), t0Light, t1Light); 
		float segmentLengthLight = t1Light / float(numSamplesLight);
		float tCurrentLight = 0.0; 
		float opticalDepthLightR = 0.0;
		float opticalDepthLightM = 0.0; 
		int jCounter = 0; 
		for (int j = 0; j < 8; ++j)
		{ 
			vec3 samplePositionLight = samplePosition + (tCurrentLight + segmentLengthLight * 0.5) * uSunDirection; 
			float heightLight = length(samplePositionLight) - EARTH_RADIUS; 
			if (heightLight < 0.0) break;
			jCounter += 1;
			opticalDepthLightR += exp(-heightLight / Hr) * segmentLengthLight; 
			opticalDepthLightM += exp(-heightLight / Hm) * segmentLengthLight; 
			tCurrentLight += segmentLengthLight; 
		} 
		if (jCounter == numSamplesLight)
		{ 
			vec3 tau = betaR * (opticalDepthR + opticalDepthLightR) + betaM * 1.1 * (opticalDepthM + opticalDepthLightM); 
			vec3 attenuation = vec3(exp(-tau.x), exp(-tau.y), exp(-tau.z)); 
			sumR += attenuation * hr; 
			sumM += attenuation * hm; 
		} 
		tCurrent += segmentLength; 
    	} 
    return (sumR * betaR * phaseR + sumM * betaM * phaseM) * 20.0; 
} 


// TERRAIN

#define TERRAIN_HEIGHT 4.0 // max height in Km
#define TERRAIN_SAMPLE_SCALE 0.02 
#define TERRAIN_LIFT -2.0 // (Km) how much to lift or drop the entire terrain
#define TERRAIN_FAR 100.0

float getTerrainHeight( in vec3 pos )
{
	vec2 uv;
	pos *= TERRAIN_SAMPLE_SCALE;
	uv.x = dot(pos, uCameraFrameRight);
	uv.y = dot(pos, uCameraFrameForward);
	float h = 0.0;
	float amp = TERRAIN_HEIGHT;

	for (int i = 0; i < 5; i ++)
	{
		h += amp * texture2D(t_PerlinNoise, uv + 0.5).x;
		amp *= 0.5;
		uv *= 2.0;
	}
	return h + TERRAIN_LIFT + EARTH_RADIUS;	
}

float getTerrainHeight_Detail( in vec3 pos )
{
	vec2 uv;
	pos *= TERRAIN_SAMPLE_SCALE;
	uv.x = dot(pos, uCameraFrameRight);
	uv.y = dot(pos, uCameraFrameForward);
	float h = 0.0;
	float amp = TERRAIN_HEIGHT;

	for (int i = 0; i < 15; i ++)
	{
		h += amp * texture2D(t_PerlinNoise, uv + 0.5).x;
		amp *= 0.5;
		uv *= 2.0;
	}
	return h; 
}

vec3 terrain_calcNormal( vec3 pos, float t )
{
	float e = 0.002;

	pos += uCameraFrameUp * getTerrainHeight_Detail(pos);

	vec3 xPos = pos + (uCameraFrameRight*e);
	vec3 xNeg = pos - (uCameraFrameRight*e);
	vec3 zPos = pos + (uCameraFrameForward*e);
	vec3 zNeg = pos - (uCameraFrameForward*e);

	xPos += (uCameraFrameUp * getTerrainHeight_Detail(xPos));
	xNeg += (uCameraFrameUp * getTerrainHeight_Detail(xNeg));
	zPos += (uCameraFrameUp * getTerrainHeight_Detail(zPos));
	zNeg += (uCameraFrameUp * getTerrainHeight_Detail(zNeg));

	vec3 xVec = normalize(xPos - xNeg);
	vec3 zVec = normalize(zPos - zNeg); 
	return normalize(cross(zVec, xVec));
}

bool terrain_isSunVisible( vec3 pos, vec3 n, vec3 dirToLight)
{
	float h = 1.0;
	float a = 0.0;
	float t = 0.0;
	float terrainHeight = TERRAIN_HEIGHT * 2.0 + TERRAIN_LIFT + EARTH_RADIUS;
	pos += n * 0.02;

	if (dot(n, dirToLight) < 0.0)
		return false;

	for(int i = 0; i < 300; i++)
	{
		a = length(pos);
		h = a - getTerrainHeight(pos);
		pos += dirToLight * h;
		if (a > terrainHeight || h < 0.01) break;
	}

	return h >= 0.01;
}

float TerrainIntersect( Ray r )
{
	vec3 pos = r.origin;
	vec3 dir = r.direction;
	float h = 0.0;
	float t = 0.0;
	float precisionFactor = 0.5;
	
	for (int i = 0; i < 300; i++)
	{
		h = length(pos) - getTerrainHeight(pos);
		if (t > TERRAIN_FAR || h < 0.01) break;
		t += h * precisionFactor;
		pos += dir * h * precisionFactor; 
	}
	return (h <= 0.01) ? t : INFINITY;
}

// WATER
/* Credit: some of the following water code is borrowed from https://www.shadertoy.com/view/Ms2SD1 posted by user 'TDM' */

#define WATER_SAMPLE_SCALE 50.0  // higher equals more repitition
#define MAX_WAVE_HEIGHT    0.001 // (in Km) Max water wave amplitude
#define WATER_FREQ         1.0   // wave density: lower = spread out, higher = close together
#define WATER_CHOPPY       2.0   // smaller beachfront-type waves, they travel in parallel
#define WATER_SPEED        0.5   // how quickly time passes
#define WATER_FAR 	   1.0	 // (in Km) how far to draw wave details
#define OCTAVE_M   mat2(1.6, 1.2, -1.2, 1.6);

float hash( vec2 p )
{
	float h = dot(p,vec2(127.1,311.7));	
    	return fract(sin(h)*43758.5453123);
}

float noise( in vec2 p )
{
	vec2 i = floor( p );
	vec2 f = fract( p );	
	vec2 u = f*f*(3.0-2.0*f);
	return -1.0+2.0*mix( mix( hash( i + vec2(0.0,0.0) ), 
		     hash( i + vec2(1.0,0.0) ), u.x),
		mix( hash( i + vec2(0.0,1.0) ), 
		     hash( i + vec2(1.0,1.0) ), u.x), u.y);
}

float water_octave( vec2 uv, float choppy )
{
	uv += noise(uv);        
	vec2 wv = 1.0 - abs(sin(uv));
	vec2 swv = abs(cos(uv));    
	wv = mix(wv, swv, clamp(wv, 0.0, 1.0));
	return pow(max(0.0, 1.0 - pow(max(0.0, wv.x * wv.y), 0.65)), choppy);
}

float getWaterHeight( vec3 pos )
{
	float freq = WATER_FREQ;
	float amp = MAX_WAVE_HEIGHT;
	float choppy = WATER_CHOPPY;
	float water_time = uTime * WATER_SPEED;
	pos *= WATER_SAMPLE_SCALE;
	vec2 uv;
	uv.x = dot(pos, uCameraFrameRight);
	uv.y = dot(pos, uCameraFrameForward);
	float d, h = 0.0;

	for(int i = 0; i < 2; i++)
	{        
		d =  water_octave((uv + water_time) * freq, choppy);
		d += water_octave((uv - water_time) * freq, choppy);
		h += d * amp;        
		uv *= OCTAVE_M; freq *= 1.9; amp *= 0.22;
		choppy = mix(choppy, 1.0, 0.2);
	}        
	
	return h + EARTH_RADIUS + 1.0; // 1.0 Km above Earth surface
}

float getWaterHeight_Detail( vec3 pos )
{
	float freq = WATER_FREQ;
	float amp = MAX_WAVE_HEIGHT;
	float choppy = WATER_CHOPPY;
	float water_time = uTime * WATER_SPEED;
	pos *= WATER_SAMPLE_SCALE;
	vec2 uv;
	uv.x = dot(pos, uCameraFrameRight);
	uv.y = dot(pos, uCameraFrameForward);
	float d, h = 0.0;

	for(int i = 0; i < 5; i++)
	{        
		d =  water_octave((uv + water_time) * freq, choppy);
		d += water_octave((uv - water_time) * freq, choppy);
		h += d * amp;        
		uv *= OCTAVE_M; freq *= 1.9; amp *= 0.22;
		choppy = mix(choppy, 1.0, 0.2);
	}

	return h;
}

vec3 water_calcNormal( vec3 pos, float t )
{
	float e = 0.01;

	pos += uCameraFrameUp * getWaterHeight_Detail(pos);

	vec3 xPos = pos + (uCameraFrameRight*e);
	vec3 xNeg = pos - (uCameraFrameRight*e);
	vec3 zPos = pos + (uCameraFrameForward*e);
	vec3 zNeg = pos - (uCameraFrameForward*e);

	xPos += (uCameraFrameUp * getWaterHeight_Detail(xPos));
	xNeg += (uCameraFrameUp * getWaterHeight_Detail(xNeg));
	zPos += (uCameraFrameUp * getWaterHeight_Detail(zPos));
	zNeg += (uCameraFrameUp * getWaterHeight_Detail(zNeg));
	
	vec3 xVec = normalize(xPos - xNeg);
	vec3 zVec = normalize(zPos - zNeg); 
	return normalize(cross(zVec, xVec));
}

float WaterIntersect( Ray r )
{
	vec3 pos = r.origin;
	vec3 dir = r.direction;
	float h = 0.0;
	float t = 0.0;
	float precisionFactor = 1.0;
	
	for (int i = 0; i < 300; i++)
	{
		h = abs(length(pos) - getWaterHeight(pos));
		if (t > WATER_FAR || h < 0.01) break;
		t += h * precisionFactor;
		pos += dir * h * precisionFactor; 
	}
	return (h <=0.01) ? t : INFINITY;
}


//-----------------------------------------------------------------------------------------------------------------------------------------------------------------------
float SceneIntersect( Ray r, inout Intersection intersec, bool checkWater )
//-----------------------------------------------------------------------------------------------------------------------------------------------------------------------
{
        float d = INFINITY;
	float t = INFINITY;
	float terrainHeight, waterHeight;
	vec3 hitPos;
	vec3 normal; 

	d = TerrainIntersect( r );

	if (d > TERRAIN_FAR)
	{
		d = SphereIntersect(EARTH_RADIUS, vec3(0), r);
		if (d < INFINITY)
		{
			hitPos = r.origin + r.direction * d;
			terrainHeight = getTerrainHeight(hitPos);
			//d = PlaneIntersect(vec4(uCameraFrameUp, terrainHeight), r);
			d = SphereIntersect(terrainHeight, vec3(0), r);
		}
	}
	if (d < t)
	{	
		t = d;
		hitPos = r.origin + r.direction * t;
		intersec.normal = terrain_calcNormal(hitPos, t);
		intersec.emission = vec3(1,0,1);
		intersec.color = vec3(0);
		intersec.type = TERRAIN;
	}
	
	if (!checkWater)
		return t;

	d = INFINITY; // reset d

	d = WaterIntersect( r );
	
	if (d > WATER_FAR)
	{
		d = SphereIntersect(EARTH_RADIUS, vec3(0), r);
		if (d < INFINITY)
		{
			hitPos = r.origin + r.direction * d;
			waterHeight = getWaterHeight(hitPos);
			//d = PlaneIntersect(vec4(uCameraFrameUp, waterHeight), r);
			d = SphereIntersect(waterHeight, vec3(0), r);
		}
	}
	if (d < t)
	{	
		t = d;
		hitPos = r.origin + r.direction * t;
		intersec.normal = water_calcNormal(hitPos, t);
		//if ( !uCameraWithinAtmosphere )
		//	intersec.normal = normalize(hitPos);
		intersec.emission = vec3(0);
		intersec.color = vec3(0.7,0.8,0.9);
		intersec.type = REFR;
	}

	if (t < INFINITY)
	return t;

	for (int i = 0; i < N_SPHERES; i++)
        {
		// Sun and Moon Spheres
		d = SphereIntersect( spheres[i].radius, spheres[i].position, r );
		if (d < t)
		{
			t = d;
			intersec.normal = normalize((r.origin + r.direction * t) - spheres[i].position);
			intersec.emission = spheres[i].emission;
			intersec.color = spheres[i].color;
			intersec.type = spheres[i].type;
		}
	}

	return t;
}


//-----------------------------------------------------------------------
vec3 CalculateRadiance( Ray r, inout uvec2 seed, vec3 starRayDir )
//-----------------------------------------------------------------------
{
	vec3 randVec = vec3(rand(seed) * 2.0 - 1.0, rand(seed) * 2.0 - 1.0, rand(seed) * 2.0 - 1.0);
	Ray cameraRay = r;
	Intersection intersec;

	vec3 accumCol = vec3(0.0);
        vec3 mask = vec3(1.0);
	vec3 n, nl, x;
	vec3 atmosphereColor = vec3(0);
	vec3 firstX = vec3(0);
	vec3 terrainColor = vec3(0);
	vec3 tdir;
	
	float nc, nt, Re;
	float t0, t1, tMax = INFINITY;
	float t = INFINITY;
	
	bool terrainHit = false;
	bool bounceIsSpecular = true;
	bool checkWater = true;
	bool isDayTime = true;
	
	if (uCameraWithinAtmosphere && dot(uSunDirection, uCameraFrameUp) < 0.0)
	{
		isDayTime = false;
	}

	if (PlanetSphereIntersect(r, EARTH_RADIUS, vec3(0), t0, t1) && t1 > 0.0) 
			tMax = max(0.0, t0);

	accumCol = computeIncidentLight(r, 0.0, tMax);

        for (int depth = 0; depth < 2; depth++)
	{
		
		t = SceneIntersect(r, intersec, checkWater);
		checkWater = false; // no need to check water a second time
		
		tMax = INFINITY; //reset tMax
		terrainHit = false;

		if (PlanetSphereIntersect(r, EARTH_RADIUS, vec3(0), t0, t1) && t1 > 0.0) 
			tMax = max(0.0, t0);

		// ray hits empty space
		if (t == INFINITY)
		{
			if (depth == 1)
			{
				accumCol = computeIncidentLight(r, 0.0, tMax);
			}

			break;	
		}
		
		// if we reached something bright, don't spawn any more rays
		if (intersec.type == LIGHT) // Sun
		{	
			//if (bounceIsSpecular)
			{
				accumCol = mix(computeIncidentLight(r, 0.0, tMax), intersec.emission, 0.5);
			}
			
			break;
		}
		
		// useful data 
		n = intersec.normal;
                nl = dot(n,r.direction) <= 0.0 ? normalize(n) : normalize(n * -1.0);
		x = r.origin + r.direction * t;
		
		
		if (intersec.type == DIFF) // Moon
		{
			vec2 uv;
			vec3 mn = n;
			uv.x = (1.0 + atan(mn.z, mn.x) / PI) * 0.5;
			uv.y = acos(mn.y) / PI;
			uv.x *= 2.5;
			float rockNoise = clamp(texture2D(t_PerlinNoise, uv).x, 0.2, 1.0);
			intersec.color = clamp(intersec.color * rockNoise, 0.0, 1.0);
			vec3 sampleSkyCol = computeIncidentLight(r, 0.0, tMax);
			accumCol = mix(intersec.color, sampleSkyCol, clamp(0.7 * (sampleSkyCol.r + sampleSkyCol.b), 0.0, 1.0));
					// * max(0.0, dot(nl, uSunDirection)); // for moon phases 
			break;
		}

		// ray hits terrain
		if (intersec.type == TERRAIN)
		{
			firstX = x;
			terrainHit = true;
			float altitude = length(x) - EARTH_RADIUS;
			vec2 uv;
			uv.x = dot(x, uCameraFrameRight);
			uv.y = dot(x, uCameraFrameForward);
			float rockNoise = texture2D(t_PerlinNoise, (0.2 * uv)).x;
			vec3 rockColor0 = vec3(0.2, 0.2, 0.2) * 0.01 * rockNoise;
			vec3 rockColor1 = vec3(0.2, 0.2, 0.2) * rockNoise;
			vec3 snowColor = vec3(0.7);
			vec3 up = normalize(x);
			float nY = max(0.0, dot(n, up));
			vec3 sunDirection = uSunDirection;
			vec3 randomSkyVec = normalize(n + (randVec * 0.2));
			vec3 skyColor = computeIncidentLight(Ray(x, randomSkyVec), 0.0, tMax);
			vec3 sunColor = computeIncidentLight(Ray(x, sunDirection), 0.0, tMax);
			sunColor = clamp(sunColor + 0.5, 0.0, 1.0);
			vec3 ambientColor;
			float terrainLayer = clamp( (altitude + (rockNoise * 1.0) * nY) / (TERRAIN_HEIGHT * 1.5 + TERRAIN_LIFT), 0.0, 1.0 );

			if (!isDayTime)
				sunDirection *= -1.0;

			if (terrainLayer > 0.7 && terrainLayer > 1.0 - nY)
			{
				intersec.color = snowColor;
				ambientColor = skyColor * max(0.0, dot(up, n)); // ambient color from sky light
				n = normalize(mix(n, sunDirection, terrainLayer * 0.5));
			}	
			else
			{
				intersec.color = mix(rockColor0, rockColor1, clamp(terrainLayer * nY, 0.0, 1.0) );
				ambientColor = intersec.color * skyColor * max(0.0, dot(randomSkyVec, n)); // ambient color from sky light
			}		
				
			vec3 shadowRayDirection = normalize(sunDirection + (0.1 * randomSkyVec * max(dot(sunDirection, up), 0.0)));
									
			if ( terrain_isSunVisible(x, n, shadowRayDirection) ) // in direct sunlight
			{
				if (isDayTime)
					terrainColor = intersec.color * sunColor * max(0.0, dot(n, normalize(sunDirection + (randVec * 0.01))));
				else 	
					terrainColor = intersec.color * 0.002 * max(0.0, dot(n, normalize(sunDirection + (randVec * 0.01))));
			}
			else terrainColor = ambientColor;
			
			if (isDayTime && altitude < 1.0) // terrain is under water
			{
				terrainColor = mix(rockColor0, terrainColor, clamp(0.1*altitude, 0.0, 1.0));
			}
			
			break;
		}
                
                if (intersec.type == REFR)  // Ideal dielectric REFRACTION
		{
			nc = 1.0; // IOR of air
			nt = 1.33; // IOR of water
			Re = calcFresnelReflectance(n, nl, r.direction, nc, nt, tdir);

			Re *= 2.0; // tweak to add more reflectivity to water
			
			if (rand(seed) < Re) // reflect ray from surface
			{
				r = Ray( x, reflect(r.direction, nl) );
				r.origin += r.direction * 1.0;
				continue;	
			}
			else // transmit ray through surface
			{
				mask *= intersec.color;
				r = Ray(x, tdir);
				r.origin += r.direction * 1.0;
				continue;
			}
			
		} // end if (intersec.type == REFR)
			
	} // end for (int depth = 0; depth < 2; depth++)
	
	// atmospheric haze effect (aerial perspective)
	float hitDistance;

	if (terrainHit)
	{
		hitDistance = distance(cameraRay.origin, firstX);
		accumCol = mix( accumCol, terrainColor, clamp( exp2( -log(hitDistance * 0.02) ), 0.0, 1.0 ) );
		// underwater fog effect
		hitDistance *= uCameraUnderWater;
		accumCol = mix( vec3(0.0,0.05,0.05), accumCol, clamp( exp2( -hitDistance * 1.0 ), 0.0, 1.0 ) );
	}

	// stars
	if (t == INFINITY)
	{
		vec3 rotatedStarDir = starRayDir;
		rotatedStarDir.x = starRayDir.x * cos(uSunAngle) + starRayDir.z * sin(uSunAngle);
		rotatedStarDir.z = starRayDir.x * -sin(uSunAngle) + starRayDir.z * cos(uSunAngle);
		vec3 starVal = stars(normalize(rotatedStarDir));
		float altitude = length(cameraRay.origin); 
		if (altitude < ATMOSPHERE_RADIUS && isDayTime)
		{
			float starAlt = EARTH_RADIUS + 15.0; // in Km
			if (altitude > starAlt)
				starVal = mix(vec3(0), starVal, clamp(exp(-(ATMOSPHERE_RADIUS - altitude) * 0.07), 0.0, 1.0));
			else
				starVal = mix(vec3(0), starVal, clamp(dot(uCameraFrameUp, -uSunDirection), 0.0, 1.0));
		
		}
			
		accumCol += starVal;
	}

	return vec3(max(vec3(0), accumCol));      
}


//-----------------------------------------------------------------------
void SetupScene(void)
//-----------------------------------------------------------------------
{
	vec3 z  = vec3(0); // no color value, black        
        vec3 L1 = vec3(1.0, 0.9, 0.8) * 5.0;// Sun Light
	spheres[0] = Sphere( 100.0, cameraPosition + (normalize( uSunDirection) * 5000.0), L1, z, LIGHT);//spherical white Light1
	spheres[1] = Sphere( 150.0, cameraPosition + (normalize(-uSunDirection) * 5000.0), z, vec3(2), DIFF);//spherical white moon	
}


// tentFilter from Peter Shirley's 'Realistic Ray Tracing (2nd Edition)' book, pg. 60		
float tentFilter(float x)
{
	if (x < 0.5) 
		return sqrt(2.0 * x) - 1.0;
	else return 1.0 - sqrt(2.0 - (2.0 * x));
}

void main( void )
{
	// not needed, three.js has a built-in uniform named cameraPosition
	//vec3 camPos   = vec3( uCameraMatrix[3][0],  uCameraMatrix[3][1],  uCameraMatrix[3][2]);

    	vec3 camRight   = normalize( vec3( uCameraMatrix[0][0],  uCameraMatrix[0][1],  uCameraMatrix[0][2]) );
	vec3 camUp      = normalize( vec3( uCameraMatrix[1][0],  uCameraMatrix[1][1],  uCameraMatrix[1][2]) );    
	vec3 camForward = normalize( vec3(-uCameraMatrix[2][0], -uCameraMatrix[2][1], -uCameraMatrix[2][2]) );

	// seed for rand(seed) function
	uvec2 seed = uvec2(uFrameCounter, uFrameCounter + 1.0) * uvec2(gl_FragCoord);

	vec2 pixelPos = vec2(0);
	vec2 pixelOffset = vec2(0);
	
	float x = rand(seed);
	float y = rand(seed);

	//if (!uCameraIsMoving)
	{
		pixelOffset.x = tentFilter(x);
		pixelOffset.y = tentFilter(y);
	}
	
	// pixelOffset ranges from -1.0 to +1.0, so only need to divide by half resolution
	pixelOffset /= (uResolution * 0.5);

	// vUv comes in the range 0.0 to 1.0, so we must map it to the range -1.0 to +1.0
	pixelPos = vUv * 2.0 - 1.0;
	vec2 starPixelPos = pixelPos;
	pixelPos += pixelOffset;

	vec3 rayDir = normalize( pixelPos.x * camRight * uULen + pixelPos.y * camUp * uVLen + camForward );
	vec3 starRayDir = normalize( starPixelPos.x * camRight * uULen + starPixelPos.y * camUp * uVLen + camForward );

	// depth of field
	vec3 focalPoint = uFocusDistance * rayDir;
	float randomAngle = rand(seed) * TWO_PI; // pick random point on aperture
	float randomRadius = rand(seed) * uApertureSize;
	vec3  randomAperturePos = ( cos(randomAngle) * camRight + sin(randomAngle) * camUp ) * randomRadius;
	// point on aperture to focal point
	vec3 finalRayDir = normalize(focalPoint - randomAperturePos);
    
	Ray ray = Ray( cameraPosition + randomAperturePos, finalRayDir );
	//Ray starRay = Ray( cameraPosition + randomAperturePos, starRayDir );
	SetupScene(); 

	// perform path tracing and get resulting pixel color
	vec3 pixelColor = CalculateRadiance( ray, seed, starRayDir );
	
	vec3 previousColor = texture2D(tPreviousTexture, vUv).rgb;
	
	if ( uCameraIsMoving )
	{
		previousColor *= 0.85; // motion-blur trail amount (old image)
		pixelColor *= 0.15; // brightness of new image (noisy)
	}
	else
	{
		previousColor *= 0.9; // motion-blur trail amount (old image)
		pixelColor *= 0.1; // brightness of new image (noisy)
	}
	
	
	out_FragColor = vec4( pixelColor + previousColor, 1.0 );	
}

		</script>
		
		
		<script>
			
			var SCREEN_WIDTH;
			var SCREEN_HEIGHT;
			var canvas, context;
			var container, stats;
			var controls;
			var pathTracingScene, screenTextureScene, screenOutputScene;
			var pathTracingUniforms, screenTextureUniforms, screenOutputUniforms;
			var PerlinNoiseTexture;
			var pathTracingDefines;
			var pathTracingGeometry, pathTracingMaterial, pathTracingMesh;
			var screenTextureGeometry, screenTextureMaterial, screenTextureMesh;
			var screenOutputGeometry, screenOutputMaterial, screenOutputMesh;
			var pathTracingRenderTarget, screenOutputRenderTarget;
			var quadCamera, worldCamera;
			var renderer, clock;
			var frameTime, elapsedTime;
			var fovScale;
			var increaseFOV = false;
			var decreaseFOV = false;
			var apertureSize = 0.0;
			var increaseAperture = false;
			var decreaseAperture = false;
			var focusDistance = 1180.0;
			var increaseFocusDist = false;
			var decreaseFocusDist = false;
			var pixelRatio = 0.5;
			var TWO_PI = Math.PI * 2;
			var sunAngle = 5.1;
			var sunDirection = new THREE.Vector3();
			var randomVector = new THREE.Vector3();
			var sampleCounter = 1.0;
			var frameCounter = 1.0;
			var keyboard = new THREEx.KeyboardState();
			var cameraIsMoving = false;
			var cameraJustStartedMoving = false;
			var cameraRecentlyMoving = false;
			var isPaused = true;
			var oldYawRotation, oldPitchRotation;
			var mobileJoystickControls = null;
			var oldDeltaX = 0, oldDeltaY = 0;
			var newDeltaX = 0, newDeltaY = 0;
			var mobileControlsMoveX = 0;
			var mobileControlsMoveY = 0;
			var stillFlagX = true, stillFlagY = true;
			var oldPinchWidthX = 0;
			var oldPinchWidthY = 0;
			var pinchDeltaX = 0;
			var pinchDeltaY = 0;
			var camFlightSpeed = 0;
			var earthRadius = 6360;
			var atmosphereRadius = 6420;
			var altitude = 2000.0;
			var oldRotationX = 0.0;
			var oldRotationY = 0.0;
			var cameraWithinAtmosphere = true;
			var UniverseUp_Y_Vec = new THREE.Vector3(0,1,0);
			var UniverseToCam_Z_Vec = new THREE.Vector3(0,0,1);
			var centerOfEarthToCameraVec = new THREE.Vector3();
			var newCameraDirectionVector = new THREE.Vector3();
			var cameraFrameRight = new THREE.Vector3();
			var cameraFrameForward = new THREE.Vector3();
			var cameraDistFromCenterOfEarth = 0.0;
			var amountToMoveCamera = 0.0;
			var canUpdateCameraAtmosphereOrientation = true;
			var canUpdateCameraSpaceOrientation = true;
			var cameraUnderWater = false;
			var fontAspect;
			var camPosToggle = false;
			var timePauseToggle = false;
			
			// the following variables will be used to calculate rotations and directions from the camera
			var cameraDirectionVector = new THREE.Vector3();//for moving where the camera is looking
			var cameraRightVector = new THREE.Vector3();//for strafing the camera right and left
			var cameraUpVector = new THREE.Vector3();//for moving camera up and down
			var cameraWorldQuaternion = new THREE.Quaternion();//for rotating scene objects to match camera's current rotation
			var cameraControlsObject;//for positioning and moving the camera itself
			var cameraControlsYawObject;//allows access to control camera's left/right movements through mobile input
			var cameraControlsPitchObject;//allows access to control camera's up/down movements through mobile input

			var PI_2 = Math.PI / 2;//used by controls below
			
			var infoElement = document.getElementById( 'info' );
			var cameraInfoElement = document.getElementById( 'cameraInfo' );
			
			var mouseControl = true;
			
			
			function onMouseWheel( event ) {

				event.preventDefault();
				event.stopPropagation();

				if ( event.deltaY > 0 ) {
					
					increaseFOV = true;
				
				} else if ( event.deltaY < 0 ) {
					
					decreaseFOV = true;
					
				}

			}
			
			
			init();
			
			
		     // function init( meshes ) {
			function init() {
				
				if ( 'ontouchstart' in window ) {
					mouseControl = false;
					pixelRatio = 0.5;
					
					mobileJoystickControls = new MobileJoystickControls ({
						//showJoystick: true,
						enableMultiTouch: true
					});	
				}

				// if on mobile device, unpause the app because there is no ESC key and no mouse capture to do
				if ( !mouseControl )
					isPaused = false;

				if (mouseControl) {

					window.addEventListener( 'wheel', onMouseWheel, false );

					document.body.addEventListener("click", function() {
						this.requestPointerLock = this.requestPointerLock || this.mozRequestPointerLock;
						this.requestPointerLock();
					}, false);

					window.addEventListener("click", function(event) {
						event.preventDefault();	
					}, false);
					window.addEventListener("dblclick", function(event) {
						event.preventDefault();	
					}, false);


					var pointerlockChange = function ( event ) {

						if ( document.pointerLockElement === document.body || 
						    document.mozPointerLockElement === document.body || document.webkitPointerLockElement === document.body ) {

							isPaused = false;

						} else {

							isPaused = true;

						}

					};

					// Hook pointer lock state change events
					document.addEventListener( 'pointerlockchange', pointerlockChange, false );
					document.addEventListener( 'mozpointerlockchange', pointerlockChange, false );
					document.addEventListener( 'webkitpointerlockchange', pointerlockChange, false );

				}
				
				canvas = document.createElement( 'canvas' );
                                context = canvas.getContext( 'webgl2' );
                                
				renderer = new THREE.WebGLRenderer( { canvas: canvas, context: context } );
				renderer.autoClear = false;
				// 1 is full resolution, 0.5 is half, 0.25 is quarter, etc. (must be > than 0.0)
				renderer.setPixelRatio(pixelRatio);
				renderer.setSize( window.innerWidth, window.innerHeight );
				//required by WebGL 2.0 for rendering to FLOAT textures
                                renderer.context.getExtension('EXT_color_buffer_float');
				
				container = document.getElementById( 'container' );
				container.appendChild( renderer.domElement );
				
				stats = new Stats();
				stats.domElement.style.position = 'fixed';
				stats.domElement.style.top = '0px';
				stats.domElement.style.cursor = "default";
				stats.domElement.style.webkitUserSelect = "none";
				stats.domElement.style.MozUserSelect = "none";
				container.appendChild( stats.domElement );
				
				window.addEventListener( 'resize', onWindowResize, false );
				
				clock = new THREE.Clock();
				
				pathTracingScene = new THREE.Scene();
				screenTextureScene = new THREE.Scene();
				screenOutputScene = new THREE.Scene();
				
				// quadCamera is simply the camera to help render the full screen quad (2 triangles),
				// hence the name.  It is an Orthographic camera that sits facing the view plane, which serves as
				// the window into our 3d world. This camera will not move or rotate for the duration of the app.
				quadCamera = new THREE.OrthographicCamera( -1, 1, 1, -1, 0, 1 );
				screenTextureScene.add(quadCamera);
				screenOutputScene.add(quadCamera);
				
				// worldCamera is the dynamic camera 3d object that will be positioned, oriented and 
				// constantly updated inside the 3d scene.  Its view will ultimately get passed back to the 
				// stationary quadCamera, which renders the scene to a fullscreen quad (made up of 2 large triangles).
				worldCamera = new THREE.PerspectiveCamera(60, window.innerWidth / window.innerHeight, 1, 1000);
				pathTracingScene.add(worldCamera);
				
				controls = new FirstPersonCameraControls( worldCamera );
							
				cameraControlsObject = controls.getObject();
				cameraControlsYawObject = controls.getYawObject();
				cameraControlsPitchObject = controls.getPitchObject();
				
				pathTracingScene.add( cameraControlsObject );

				// camera starts in space
				cameraControlsObject.position.set(0, 0, earthRadius + 5000.0); // in Km
				cameraControlsYawObject.rotation.y = 0.0;
				cameraControlsPitchObject.rotation.x = 0.0;
			
				oldYawRotation = 0.0;
				oldPitchRotation = 0.0;
				
				// now that we moved and rotated the camera, the following line force-updates the camera's matrix,
				//  and prevents rendering the very first frame in the old default camera position/orientation
				cameraControlsObject.updateMatrixWorld(true);
				
				pathTracingRenderTarget = new THREE.WebGLRenderTarget( (window.innerWidth * pixelRatio), (window.innerHeight * pixelRatio), {
					minFilter: THREE.NearestFilter,
					magFilter: THREE.NearestFilter,
					format: THREE.RGBAFormat,
					type: THREE.FloatType,
					depthBuffer: false,
					stencilBuffer: false
				} );
				pathTracingRenderTarget.texture.generateMipmaps = false;
				
				screenTextureRenderTarget = new THREE.WebGLRenderTarget( (window.innerWidth * pixelRatio), (window.innerHeight * pixelRatio), {
					minFilter: THREE.NearestFilter, 
					magFilter: THREE.NearestFilter,
					format: THREE.RGBAFormat,
					type: THREE.FloatType,
					depthBuffer: false,
					stencilBuffer: false
				} );
				screenTextureRenderTarget.texture.generateMipmaps = false;


				PerlinNoiseTexture = new THREE.TextureLoader().load( 'textures/perlin256.png' );
				PerlinNoiseTexture.wrapS = THREE.RepeatWrapping;
				PerlinNoiseTexture.wrapT = THREE.RepeatWrapping;
				PerlinNoiseTexture.flipY = false;
				//PerlinNoiseTexture.minFilter = THREE.LinearFilter;
				//PerlinNoiseTexture.magFilter = THREE.LinearFilter;
				//PerlinNoiseTexture.generateMipmaps = false;
				
				
				pathTracingGeometry = new THREE.PlaneBufferGeometry( 2, 2 );

				pathTracingUniforms = {
					
					tPreviousTexture: { type: "t", value: screenTextureRenderTarget.texture },
					
					t_PerlinNoise: { type: "t", value: PerlinNoiseTexture },
					
					uCameraIsMoving: { type: "b1", value: false },
					uCameraJustStartedMoving: { type: "b1", value: false },
					uCameraWithinAtmosphere: { type: "b1", value: cameraWithinAtmosphere },
					
					uTime: { type: "f", value: 0.0 },
					uSampleCounter: { type: "f", value: 0.0 },
					uFrameCounter: { type: "f", value: 1.0 },
					uULen: { type: "f", value: 1.0 },
					uVLen: { type: "f", value: 1.0 },
					uApertureSize: { type: "f", value: 0.0 },
					uFocusDistance: { type: "f", value: 1180.0 },
					uCameraUnderWater: { type: "f", value: 0.0 },
					uSunAngle: { type: "f", value: 0.0 },
					
					uResolution: { type: "v2", value: new THREE.Vector2() },
					
					uRandomVector: { type: "v3", value: new THREE.Vector3() },
					uSunDirection: { type: "v3", value: new THREE.Vector3() },
					uCameraFrameRight: { type: "v3", value: new THREE.Vector3() },
					uCameraFrameForward: { type: "v3", value: new THREE.Vector3() },
					uCameraFrameUp: { type: "v3", value: new THREE.Vector3() },
					
					uCameraMatrix: { type: "m4", value: new THREE.Matrix4() }
				};
				
				/*
				pathTracingDefines = {
					NUMBER_OF_TRIANGLES: total_number_of_triangles
				};
				*/
			
				pathTracingMaterial = new THREE.ShaderMaterial( {
					uniforms: pathTracingUniforms,
					//defines: pathTracingDefines,
					vertexShader: document.getElementById( 'pathTracingVertexShader' ).textContent,
					fragmentShader: document.getElementById( 'pathTracingFragmentShader' ).textContent,
				        depthTest: false,
                                        depthWrite: false
                                } );

				pathTracingMesh = new THREE.Mesh( pathTracingGeometry, pathTracingMaterial );
				pathTracingScene.add( pathTracingMesh );
				
				
				
				// the following keeps the large scene ShaderMaterial quad right in front 
				//   of the camera at all times. This is necessary because without it, the scene 
				//   quad will fall out of view and get clipped when the camera rotates past 180 degrees.
				worldCamera.add( pathTracingMesh );
				
				
				
				screenTextureGeometry = new THREE.PlaneBufferGeometry( 2, 2 );
				
				screenTextureMaterial = new THREE.ShaderMaterial( {
					uniforms: screenTextureShader.uniforms,
					vertexShader: screenTextureShader.vertexShader,
					fragmentShader: screenTextureShader.fragmentShader,
					depthWrite: false,
					depthTest: false
				} );
				
				screenTextureMaterial.uniforms.tTexture0.value = pathTracingRenderTarget.texture;
				
				screenTextureMesh = new THREE.Mesh(screenTextureGeometry, screenTextureMaterial);
				screenTextureScene.add(screenTextureMesh);
				
				
				
				screenOutputGeometry = new THREE.PlaneBufferGeometry( 2, 2 );
				
				screenOutputMaterial = new THREE.ShaderMaterial( {
					uniforms: screenOutputShader.uniforms,
					vertexShader: screenOutputShader.vertexShader,
					fragmentShader: screenOutputShader.fragmentShader,
					depthWrite: false,
					depthTest: false
				} );
				
				screenOutputMaterial.uniforms.tTexture0.value = pathTracingRenderTarget.texture;
				
				screenOutputMesh = new THREE.Mesh(screenOutputGeometry, screenOutputMaterial);
				screenOutputScene.add(screenOutputMesh);
				

				/*
				// Fullscreen API
				document.addEventListener("click", function() {
					
					if ( !document.fullscreenElement && !document.mozFullScreenElement && !document.webkitFullscreenElement ) {

						if (document.documentElement.requestFullscreen) {
							document.documentElement.requestFullscreen();
							
						} else if (document.documentElement.mozRequestFullScreen) {
							document.documentElement.mozRequestFullScreen();
						
						} else if (document.documentElement.webkitRequestFullscreen) {
							document.documentElement.webkitRequestFullscreen();
						
						}

					}
				});
				*/
				
				// onWindowResize() must be at the end of the init() function
				onWindowResize();
				
				// everything is set up, now we can start animating
				animate();
				
			} // end function init()
			
			
			function toggleCameraPos() {

				camPosToggle = !camPosToggle;
				
				if (camPosToggle) {
					// camera on planet surface
					cameraControlsObject.position.set(-100, 0, earthRadius + 2.0); // in Km
					sunAngle = 0.5;
					canUpdateCameraAtmosphereOrientation = true;
					document.getElementById("cameraPosButton").innerHTML = "Teleport to Space";
				}	
				else {
					// camera in space
					cameraControlsObject.position.set(0, 0, earthRadius + 5000.0); // in Km
					sunAngle = 0.0;
					canUpdateCameraSpaceOrientation = true;
					document.getElementById("cameraPosButton").innerHTML = "Teleport to Surface";
				}

			}

			function toggleTimePause() {

				timePauseToggle = !timePauseToggle;

				if (timePauseToggle) {
					document.getElementById("timePauseButton").innerHTML = "Resume Time";
				}	
				else {
					document.getElementById("timePauseButton").innerHTML = "Pause Time";
				}

			}
			
			function onWindowResize( event ) {
				
				SCREEN_WIDTH = window.innerWidth;
				SCREEN_HEIGHT = window.innerHeight;
				
				renderer.setPixelRatio(pixelRatio);
				renderer.setSize( SCREEN_WIDTH, SCREEN_HEIGHT );
				
				fontAspect = (SCREEN_WIDTH / 175) * (SCREEN_HEIGHT / 200);
				if (fontAspect > 25) fontAspect = 25;
				if (fontAspect < 4) fontAspect = 4;
				fontAspect *= 2;
				
				pathTracingUniforms.uResolution.value.x = renderer.context.drawingBufferWidth;
				pathTracingUniforms.uResolution.value.y = renderer.context.drawingBufferHeight;
				
				pathTracingRenderTarget.setSize( renderer.context.drawingBufferWidth, renderer.context.drawingBufferHeight );
				screenTextureRenderTarget.setSize( renderer.context.drawingBufferWidth, renderer.context.drawingBufferHeight );
				
				worldCamera.aspect = renderer.domElement.clientWidth / renderer.domElement.clientHeight;
				worldCamera.updateProjectionMatrix();
				
				// the following scales all scene objects by the worldCamera's field of view,
				// taking into account the screen aspect ratio and multiplying the uniform uULen,
				// the x-coordinate, by this ratio
				fovScale = worldCamera.fov * 0.5 * (Math.PI / 180.0);
				pathTracingUniforms.uVLen.value = Math.tan(fovScale);
				pathTracingUniforms.uULen.value = pathTracingUniforms.uVLen.value * worldCamera.aspect;

				if ( !mouseControl ) {
					
					button1Element.style.display = "";
					button2Element.style.display = "";
					button3Element.style.display = "";
					button4Element.style.display = "";
					button5Element.style.display = "";
					button6Element.style.display = "";
					// check if mobile device is in portrait or landscape mode and position buttons accordingly
					if (SCREEN_WIDTH < SCREEN_HEIGHT) {
						
						button1Element.style.right = 36 + "%";
						button2Element.style.right = 2 + "%";
						button3Element.style.right = 16 + "%";
						button4Element.style.right = 16 + "%";
						button5Element.style.right = 3 + "%";
						button6Element.style.right = 3 + "%";

						button1Element.style.bottom = 5 + "%";
						button2Element.style.bottom = 5 + "%";
						button3Element.style.bottom = 13 + "%";
						button4Element.style.bottom = 2 + "%";
						button5Element.style.bottom = 25 + "%";
						button6Element.style.bottom = 18 + "%";
						
					}
					else {
						
						button1Element.style.right = 22 + "%";
						button2Element.style.right = 3 + "%";
						button3Element.style.right = 11 + "%";
						button4Element.style.right = 11 + "%";
						button5Element.style.right = 3 + "%";
						button6Element.style.right = 3 + "%";

						button1Element.style.bottom = 10 + "%";
						button2Element.style.bottom = 10 + "%";
						button3Element.style.bottom = 26 + "%";
						button4Element.style.bottom = 4 + "%";
						button5Element.style.bottom = 48 + "%";
						button6Element.style.bottom = 34 + "%";
						
					}
					
				} // end if ( !mouseControl ) {
				
			} // end function onWindowResize( event )
			
			
			
			function animate() {
				
				requestAnimationFrame( animate );
				
				frameTime = clock.getDelta();
				
				elapsedTime = clock.getElapsedTime() % 1000;
				
				// reset flags
				cameraIsMoving = false;
				cameraJustStartedMoving = false;
				
				// check user controls
				if (mouseControl) {
					// movement detected
					if ( oldYawRotation != cameraControlsYawObject.rotation.y || 
					      oldPitchRotation != cameraControlsPitchObject.rotation.x ) {
	
						cameraIsMoving = true;
					}
					
					// save state for next frame
					oldYawRotation = cameraControlsYawObject.rotation.y;
					oldPitchRotation = cameraControlsPitchObject.rotation.x;
					
				} // end if (mouseControl)
			
				// if not playing on desktop, get input from the mobileJoystickControls
				if ( !mouseControl ) {

					newDeltaX = joystickDeltaX;
					
					if (newDeltaX) {
						
						mobileControlsMoveX = oldDeltaX - newDeltaX;
						// smooth out jerkiness if camera was sitting still 
						if (stillFlagX) {
							mobileControlsMoveX *= 0.1;
							stillFlagX = false;
						}
						// mobileJoystick X movement (left and right) affects camera rotation around the Y axis
						cameraControlsYawObject.rotateOnWorldAxis(cameraControlsYawObject.up, mobileControlsMoveX * 0.01);
					}
					
					newDeltaY = joystickDeltaY;
					
					if (newDeltaY) {
						
						mobileControlsMoveY = oldDeltaY - newDeltaY;
						// smooth out jerkiness if camera was sitting still
						if (stillFlagY) {
							mobileControlsMoveY *= 0.1;
							stillFlagY = false;
						}
						// mobileJoystick Y movement (up and down) affects camera rotation around the X axis	
						cameraControlsPitchObject.rotation.x += (mobileControlsMoveY) * 0.01;
					}
					
					// clamp the camera's vertical movement (around the x-axis) to the scene's 'ceiling' and 'floor',
					// so you can't accidentally flip the camera upside down
					cameraControlsPitchObject.rotation.x = Math.max( - PI_2, Math.min( PI_2, cameraControlsPitchObject.rotation.x ) );
					
					// save state for next frame
					oldDeltaX = newDeltaX;
					oldDeltaY = newDeltaY;
					
					// movement detected
					if ( newDeltaX || newDeltaY ) {
						
						cameraIsMoving = true;
					}
					else {
						stillFlagX = true;
						stillFlagY = true;
					}
					
					newPinchWidthX = pinchWidthX;
					newPinchWidthY = pinchWidthY;
					pinchDeltaX = newPinchWidthX - oldPinchWidthX;
					pinchDeltaY = newPinchWidthY - oldPinchWidthY;
					
					if( Math.abs(pinchDeltaX) > Math.abs(pinchDeltaY) ) {
						if (pinchDeltaX < -3) increaseFOV = true;
						if (pinchDeltaX >  3) decreaseFOV = true;
					}
					
					if( Math.abs(pinchDeltaY) >= Math.abs(pinchDeltaX) ) {
						if (pinchDeltaY >  1) increaseAperture = true;
						if (pinchDeltaY < -1) decreaseAperture = true;
					}
					
					// save state for next frame
					oldPinchWidthX = newPinchWidthX;
					oldPinchWidthY = newPinchWidthY;
					
				} // end if ( !mouseControl )
				
				// this gives us a vector in the direction that the camera is pointing,
				// which will be useful for moving the camera 'forward' and shooting projectiles in that direction
				controls.getDirection(cameraDirectionVector);
				cameraDirectionVector.normalize();
				controls.getUpVector(cameraUpVector);
				cameraUpVector.normalize();
				controls.getRightVector(cameraRightVector);
				cameraRightVector.normalize();

				// the following gives us a rotation quaternion (4D vector), which will be useful for 
				// rotating scene objects to match the camera's rotation
				worldCamera.getWorldQuaternion(cameraWorldQuaternion);
				
				// allow flying camera
				if ( (keyboard.pressed('W') || button3Pressed) && !(keyboard.pressed('S') || button4Pressed) ) {

					cameraControlsObject.position.add(cameraDirectionVector.multiplyScalar(camFlightSpeed * frameTime));
					cameraIsMoving = true;
				}
				if ( (keyboard.pressed('S') || button4Pressed) && !(keyboard.pressed('W') || button3Pressed) ) {

					cameraControlsObject.position.sub(cameraDirectionVector.multiplyScalar(camFlightSpeed * frameTime));
					cameraIsMoving = true;
				}
				if ( (keyboard.pressed('A') || button1Pressed) && !(keyboard.pressed('D') || button2Pressed) ) {

					cameraControlsObject.position.sub(cameraRightVector.multiplyScalar(camFlightSpeed * frameTime));
					cameraIsMoving = true;
				}
				if ( (keyboard.pressed('D') || button2Pressed) && !(keyboard.pressed('A') || button1Pressed) ) {

					cameraControlsObject.position.add(cameraRightVector.multiplyScalar(camFlightSpeed * frameTime));
					cameraIsMoving = true;
				}
				if ( keyboard.pressed('Q') && !keyboard.pressed('Z') ) {

					cameraControlsObject.position.add(cameraUpVector.multiplyScalar(camFlightSpeed * frameTime));
					cameraIsMoving = true;
				}
				if ( keyboard.pressed('Z') && !keyboard.pressed('Q') ) {

					cameraControlsObject.position.sub(cameraUpVector.multiplyScalar(camFlightSpeed * frameTime));
					cameraIsMoving = true;
				}

				// reset vectors that may have changed
				cameraControlsObject.updateMatrixWorld(true);
				controls.getDirection(cameraDirectionVector);
				cameraDirectionVector.normalize();

				centerOfEarthToCameraVec.copy(cameraControlsObject.position);
				cameraDistFromCenterOfEarth = centerOfEarthToCameraVec.length();
				centerOfEarthToCameraVec.normalize();

				altitude = Math.max(0.001, cameraDistFromCenterOfEarth - earthRadius);
				camFlightSpeed = Math.max(0.1, altitude * 0.3);
				camFlightSpeed = Math.min(camFlightSpeed, 500.0);

				// camera within atmosphere
				if (cameraDistFromCenterOfEarth < atmosphereRadius)
				{
					cameraWithinAtmosphere = true;
					canUpdateCameraSpaceOrientation = true;
					oldRotationY = cameraControlsYawObject.rotation.y;
					//oldRotationX = cameraControlsPitchObject.rotation.x;

					if (canUpdateCameraAtmosphereOrientation)
					{
						cameraControlsObject.quaternion.setFromUnitVectors(UniverseUp_Y_Vec, centerOfEarthToCameraVec);
						cameraControlsObject.updateMatrixWorld(true);
						
						cameraControlsObject.up.copy(centerOfEarthToCameraVec);
						cameraControlsObject.rotateOnWorldAxis(cameraControlsObject.up, cameraControlsObject.rotation.y + oldRotationY);
						cameraControlsPitchObject.rotation.x = 0;
						cameraControlsObject.updateMatrixWorld(true);

						pathTracingUniforms.uCameraFrameRight.value.set(
							cameraControlsObject.matrixWorld.elements[0],
							cameraControlsObject.matrixWorld.elements[1],
							cameraControlsObject.matrixWorld.elements[2] );

						pathTracingUniforms.uCameraFrameUp.value.set(
							cameraControlsObject.matrixWorld.elements[4],
							cameraControlsObject.matrixWorld.elements[5],
							cameraControlsObject.matrixWorld.elements[6] );

						pathTracingUniforms.uCameraFrameForward.value.set(
							cameraControlsObject.matrixWorld.elements[8],
							cameraControlsObject.matrixWorld.elements[9],
							cameraControlsObject.matrixWorld.elements[10] );

					}

					canUpdateCameraAtmosphereOrientation = false;
				}
				else { // camera in space
					cameraWithinAtmosphere = false;
					canUpdateCameraAtmosphereOrientation = true;
					oldRotationY = cameraControlsYawObject.rotation.y;

					if (canUpdateCameraSpaceOrientation)
					{
						//cameraControlsObject.quaternion.setFromUnitVectors(centerOfEarthToCameraVec, UniverseToCam_Z_Vec);
						cameraControlsObject.rotation.set(0,0,0);
						cameraControlsObject.up.set(0, 1, 0);
						cameraControlsObject.updateMatrixWorld(true);
					
						//cameraControlsObject.rotateOnWorldAxis(cameraControlsObject.up, cameraControlsObject.rotation.y + oldRotationY);
						cameraControlsPitchObject.rotation.x = 0;
						cameraControlsObject.updateMatrixWorld(true);

						pathTracingUniforms.uCameraFrameRight.value.set(1, 0, 0);
						pathTracingUniforms.uCameraFrameUp.value.set(0, 1, 0);
						pathTracingUniforms.uCameraFrameForward.value.set(0, -1, 0);
					}
					canUpdateCameraSpaceOrientation = false;
					
				}

				if (cameraDistFromCenterOfEarth < (earthRadius + 0.001))
				{
					amountToMoveCamera = (earthRadius + 0.001) - cameraDistFromCenterOfEarth;
					cameraControlsObject.position.add(centerOfEarthToCameraVec.multiplyScalar(amountToMoveCamera));
				}
				
				if ( (keyboard.pressed('up') || button5Pressed) && !(keyboard.pressed('down') || button6Pressed) ) {
					
					increaseFocusDist = true;
				}
				if ( (keyboard.pressed('down') || button6Pressed) && !(keyboard.pressed('up') || button5Pressed) ) {
					
					decreaseFocusDist = true;
				}
				if ( keyboard.pressed('right') && !keyboard.pressed('left') ) {
					
					increaseAperture = true;
				}
				if ( keyboard.pressed('left') && !keyboard.pressed('right') ) {
					
					decreaseAperture = true;
				}
				
				if ( increaseFOV ) {
					worldCamera.fov ++;
					if (worldCamera.fov > 150)
						worldCamera.fov = 150;
					fovScale = worldCamera.fov * 0.5 * (Math.PI / 180.0);
					pathTracingUniforms.uVLen.value = Math.tan(fovScale);
					pathTracingUniforms.uULen.value = pathTracingUniforms.uVLen.value * worldCamera.aspect;
				
					cameraIsMoving = true;
					increaseFOV = false;
				}
				if ( decreaseFOV ) {
					worldCamera.fov --;
					if (worldCamera.fov < 1)
						worldCamera.fov = 1;
					fovScale = worldCamera.fov * 0.5 * (Math.PI / 180.0);
					pathTracingUniforms.uVLen.value = Math.tan(fovScale);
					pathTracingUniforms.uULen.value = pathTracingUniforms.uVLen.value * worldCamera.aspect;
					
					cameraIsMoving = true;
					decreaseFOV = false;
				}
				
				if (increaseFocusDist) {
					focusDistance += 2;
					pathTracingUniforms.uFocusDistance.value = focusDistance;
					cameraIsMoving = true;
					increaseFocusDist = false;
				}
				if (decreaseFocusDist) {
					focusDistance -= 2;
					if (focusDistance < 2)
						focusDistance = 2;
					pathTracingUniforms.uFocusDistance.value = focusDistance;
					cameraIsMoving = true;
					decreaseFocusDist = false;
				}
				
				if (increaseAperture) {
					apertureSize += 1.0;
					if (apertureSize > 200.0)
						apertureSize = 200.0;
					pathTracingUniforms.uApertureSize.value = apertureSize;
					cameraIsMoving = true;
					increaseAperture = false;
				}
				if (decreaseAperture) {
					apertureSize -= 1.0;
					if (apertureSize < 0.0)
						apertureSize = 0.0;
					pathTracingUniforms.uApertureSize.value = apertureSize;
					cameraIsMoving = true;
					decreaseAperture = false;
				}
				
				
				if ( cameraIsMoving ) {
					
					sampleCounter = 1.0;
					frameCounter  += 1.0;
					
					if ( !cameraRecentlyMoving ) {
						cameraJustStartedMoving = true;
						cameraRecentlyMoving = true;
					}
					
				}
				
				if ( !cameraIsMoving ) {
	
					sampleCounter = 1.0; // for continuous updating of image
					//sampleCounter += 1.0; // for progressive refinement of image
					frameCounter  += 1.0;
					if (cameraRecentlyMoving)
						frameCounter = 1.0;

					cameraRecentlyMoving = false;
					
				}

				if (altitude < 1.0) // in Km
					cameraUnderWater = 1.0;
				else cameraUnderWater = 0.0;
				
				if (!timePauseToggle)
					sunAngle += (0.05 * frameTime) % TWO_PI;
				sunDirection.set(Math.cos(sunAngle), 0, Math.sin(sunAngle));
				sunDirection.normalize();

				pathTracingUniforms.uCameraUnderWater.value = cameraUnderWater;
				pathTracingUniforms.uSunAngle.value = sunAngle;
				pathTracingUniforms.uSunDirection.value.copy(sunDirection);
				pathTracingUniforms.uTime.value = elapsedTime;
				pathTracingUniforms.uCameraIsMoving.value = cameraIsMoving;
				pathTracingUniforms.uCameraJustStartedMoving.value = cameraJustStartedMoving;
				pathTracingUniforms.uCameraWithinAtmosphere.value = cameraWithinAtmosphere;
				pathTracingUniforms.uSampleCounter.value = sampleCounter;
				pathTracingUniforms.uFrameCounter.value = frameCounter;
				pathTracingUniforms.uRandomVector.value.copy(randomVector.set( Math.random(), Math.random(), Math.random() ));

				// CAMERA
				cameraControlsObject.updateMatrixWorld(true);			
				pathTracingUniforms.uCameraMatrix.value.copy( worldCamera.matrixWorld );
				screenOutputMaterial.uniforms.uOneOverSampleCounter.value = 1.0 / sampleCounter;
					     // 1.0 Km
				if (altitude >= 1.0) { 
					cameraInfoElement.innerHTML = "Altitude: " + altitude.toFixed(1) + " Kilometers | " + (altitude * 0.621371).toFixed(1) + " Miles" +
					" (Water Level = 1 Km)" + "<br>" +
					"FOV: " + worldCamera.fov + " / Aperture: " + apertureSize.toFixed(2) + " / FocusDistance: " + focusDistance + "<br>" +
				 	"Samples: " + sampleCounter;
				}
				else {
					cameraInfoElement.innerHTML = "Altitude: " + Math.floor(1000 * altitude) + " meters | " + Math.floor(1000 * altitude * 3.28084) + " feet" + "<br>" +
					"FOV: " + worldCamera.fov + " / Aperture: " + apertureSize.toFixed(2) + " / FocusDistance: " + focusDistance + "<br>" +
				 	"Samples: " + sampleCounter;
				}
				
				
				// RENDERING in 3 steps
				
				// STEP 1
				// Perform PathTracing and Render(save) into pathTracingRenderTarget
				// Read previous screenTextureRenderTarget to use as a new starting point to blend with
				renderer.render( pathTracingScene, worldCamera, pathTracingRenderTarget );	
				
				// STEP 2
				// Render(copy) the final pathTracingScene output(above) into screenTextureRenderTarget
				// This will be used as a new starting point for Step 1 above
				renderer.render( screenTextureScene, quadCamera, screenTextureRenderTarget );
				
				// STEP 3
				// Render full screen quad with generated pathTracingRenderTarget in STEP 1 above.
				// After the image is gamma corrected, it will be shown on the screen as the final accumulated output
				renderer.render( screenOutputScene, quadCamera );
						
				
				stats.update();
					
				
			} // end function animate()

		</script>

	</body>
</html>
