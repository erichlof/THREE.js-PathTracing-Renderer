<!DOCTYPE html>
<html lang="en">
	<head>
		<title>three.js PathTracing Renderer - Billiard Table</title>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, user-scalable=no, initial-scale=1">
		<style>

			html, body {
				width: 100%;
				height: 100%;
				font-family: Monospace;
				background-color: #000;
				color: #000;
				margin: 0px;
				overflow: hidden;
				touch-action: none;
			}
			
			#info {
				position: absolute;
				top: 5px;
				width: 100%;
				text-align: center;
				color: #ffffff;
			}		
			
		</style>
	</head>
	<body>
		
		<div id="container"> </div>
		<div id="info">three.js PathTracing Renderer - Billiard Table</div>
		
		<div id="cameraInfo" style="position:fixed; left:3%; bottom:2%; font-family:arial; color:rgb(255,255,255);">
		FOV: 55 / Aperture: 0.00 / FocusDistance: 132 <br> 
		Samples: 0
		</div>
		
		<script src="js/three.min.js"> </script>
		<script src="js/pathTracingCommon.js"> </script>
		<script src="js/threex.keyboardstate.js"> </script>
		<script src="js/FirstPersonCameraControls.js"> </script>
		<script src="js/MobileJoystickControls.js"> </script>
		<script src="js/stats.min.js"> </script>
		
		
		<script id="pathTracingVertexShader" type="x-shader/x-vertex">
		
precision highp float;
precision highp int;

varying vec2 vUv;

void main()
{
	vUv = uv;
	gl_Position = vec4( position, 1.0 );
}

		</script>
		
		
		
		<script id="pathTracingFragmentShader" type="x-shader/x-fragment">
				
precision highp float;
precision highp int;
precision highp sampler2D;

uniform mat4 uShortBoxInvMatrix;
uniform mat3 uShortBoxNormalMatrix;
uniform mat4 uTallBoxInvMatrix;
uniform mat3 uTallBoxNormalMatrix;

#include <pathtracing_uniforms_and_defines>

uniform sampler2D tClothTexture;
uniform sampler2D tDarkWoodTexture;
uniform sampler2D tLightWoodTexture;

#define N_SPHERES 3
#define N_ELLIPSOIDS 2
#define N_PLANES 1
#define N_QUADS 6
#define N_BOXES 9
#define N_CONES 5


//-----------------------------------------------------------------------

struct Ray { vec3 origin; vec3 direction; };
struct Sphere { float radius; vec3 position; vec3 emission; vec3 color; float roughness; int type; };
struct Ellipsoid { vec3 radii; vec3 position; vec3 emission; vec3 color; float roughness; int type; };
struct Plane { vec4 pla; vec3 emission; vec3 color; float roughness; int type; };
struct Quad { vec3 normal; vec3 v0; vec3 v1; vec3 v2; vec3 v3; vec3 emission; vec3 color; float roughness; int type; };
struct Box { vec3 minCorner; vec3 maxCorner; vec3 emission; vec3 color; float roughness; int type; };
struct Cone { vec3 pos0; float radius0; vec3 pos1; float radius1; vec3 emission; vec3 color; float roughness; int type; };
struct Intersection { vec3 normal; vec3 emission; vec3 color; float roughness; int type; };

Sphere spheres[N_SPHERES];
Ellipsoid ellipsoids[N_ELLIPSOIDS];
Plane planes[N_PLANES];
Quad quads[N_QUADS];
Box boxes[N_BOXES];
Cone cones[N_CONES];

#include <pathtracing_random_functions>

#include <pathtracing_plane_intersect>

#include <pathtracing_sphere_intersect>

#include <pathtracing_ellipsoid_intersect>

#include <pathtracing_quad_intersect>

#include <pathtracing_box_intersect>

#include <pathtracing_cone_intersect>


//-----------------------------------------------------------------------
float SceneIntersect( Ray r, inout Intersection intersec )
//-----------------------------------------------------------------------
{
	float d;
	float t = INFINITY;
	vec3 n;
	
	for (int i = 0; i < N_QUADS; i++)
        {
		d = QuadIntersect( quads[i].v0, quads[i].v1, quads[i].v2, quads[i].v3, quads[i].normal, r );
		if (d < t)
		{
			t = d;
			intersec.normal = (quads[i].normal);
			intersec.emission = quads[i].emission;
			intersec.color = quads[i].color;
			intersec.roughness = quads[i].roughness;
			intersec.type = quads[i].type;
		}
	}
	
	for (int i = 0; i < N_SPHERES; i++)
        {
		d = SphereIntersect( spheres[i].radius, spheres[i].position, r );
		if (d < t)
		{
			t = d;
			intersec.normal = normalize((r.origin + r.direction * t) - spheres[i].position);
			intersec.emission = spheres[i].emission;
			intersec.color = spheres[i].color;
			intersec.roughness = spheres[i].roughness;
			intersec.type = spheres[i].type;
		}
        }
	
	for (int i = 0; i < N_ELLIPSOIDS; i++)
        {
		d = EllipsoidIntersect( ellipsoids[i].radii, ellipsoids[i].position, r );
		if (d < t)
		{
			t = d;
			intersec.normal = normalize( ((r.origin + r.direction * t) - ellipsoids[i].position) / (ellipsoids[i].radii * ellipsoids[i].radii) );
			intersec.emission = ellipsoids[i].emission;
			intersec.color = ellipsoids[i].color;
			intersec.roughness = ellipsoids[i].roughness;
			intersec.type = ellipsoids[i].type;
		}
	}
	
	for (int i = 0; i < N_BOXES; i++)
        {
	
		d = BoxIntersect( boxes[i].minCorner, boxes[i].maxCorner, r, n );
		if (d < t)
		{
			t = d;
			intersec.normal = normalize(n);
			intersec.emission = boxes[i].emission;
			intersec.color = boxes[i].color;
			intersec.roughness = boxes[i].roughness;
			intersec.type = boxes[i].type;
		}
        }
	
	for (int i = 0; i < N_PLANES; i++)
        {
		d = PlaneIntersect( planes[i].pla, r );
		if (d < t)
		{
			t = d;
			intersec.normal = normalize(planes[i].pla.xyz);
			intersec.emission = planes[i].emission;
			intersec.color = planes[i].color;
			intersec.roughness = planes[i].roughness;
			intersec.type = planes[i].type;
		}
        }
	
	for (int i = 0; i < N_CONES; i++)
        {
		d = ConeIntersect( cones[i].pos0, cones[i].radius0, cones[i].pos1, cones[i].radius1, r, n );
		if (d < t)
		{
			t = d;
			intersec.normal = normalize(n);
			intersec.emission = cones[i].emission;
			intersec.color = cones[i].color;
			intersec.roughness = cones[i].roughness;
			intersec.type = cones[i].type;
		}
        }
	
	return t;
	
} // end float SceneIntersect( Ray r, inout Intersection intersec )


//-----------------------------------------------------------------------
bool SceneIntersect_IsLightVisible( Ray r, float t )
//-----------------------------------------------------------------------
{
	float d;
	vec3 n;
	bool result = true;
	
	for (int i = 0; i < N_QUADS; i++)
        {
		d = QuadIntersect( quads[i].v0, quads[i].v1, quads[i].v2, quads[i].v3, quads[i].normal, r );
		if (d < t && quads[i].type != LIGHT)
			result = false;	
	}
	
	for (int i = 0; i < N_SPHERES; i++)
        {
		d = SphereIntersect( spheres[i].radius, spheres[i].position, r );
		if (d < t && spheres[i].type != LIGHT)
			result = false;	
        }
	
	for (int i = 0; i < N_BOXES; i++)
        {
	
		d = BoxIntersect( boxes[i].minCorner, boxes[i].maxCorner, r, n );
		if (d < t && boxes[i].type != LIGHT)
			result = false;	
        }
	
	for (int i = 0; i < N_PLANES; i++)
        {
		d = PlaneIntersect( planes[i].pla, r );
		if (d < t && planes[i].type != LIGHT)
			result = false;	
        }
	
	for (int i = 0; i < N_ELLIPSOIDS; i++)
        {
		d = EllipsoidIntersect( ellipsoids[i].radii, ellipsoids[i].position, r );
		if (d < t && ellipsoids[i].type != LIGHT)
			result = false;	
	}
	
	for (int i = 0; i < N_CONES; i++)
        {
		d = ConeIntersect( cones[i].pos0, cones[i].radius0, cones[i].pos1, cones[i].radius1, r, n );
		if (d < t && cones[i].type != LIGHT)
			result = false;	
        }
	
	return result;
	
} // end bool SceneIntersect_IsLightVisible( Ray r, float t )


//#include <pathtracing_direct_lighting_quad>
vec3 calcDirectLightingQuad(vec3 mask, vec3 x, vec3 nl, Quad light, inout float seed)
{
	vec3 dirLight = vec3(0.0);
	vec3 randPointOnLight;
	randPointOnLight.x = mix(light.v0.x, light.v1.x, rand(seed));
	randPointOnLight.y = light.v0.y;
	randPointOnLight.z = mix(light.v0.z, light.v3.z, rand(seed));
	vec3 srDir = normalize(randPointOnLight - x);
	
	// cast shadow ray from intersection point	
	Ray shadowRay = Ray(x, srDir);
	shadowRay.origin += nl * 2.0;
	vec3 d = randPointOnLight - shadowRay.origin;
	if ( SceneIntersect_IsLightVisible(shadowRay, length(d)) )
	{
		float r2 = distance(light.v0, light.v1) * distance(light.v0, light.v3);
		float weight = clamp(r2 / dot(d, d), 0.0, 1.0);
		dirLight = mask * light.emission * weight * max(dot(nl, srDir), 0.01);
	}

	return dirLight;
}


//-----------------------------------------------------------------------
vec3 CalculateRadiance( Ray r, inout float seed )
//-----------------------------------------------------------------------
{
	vec3 randVec = vec3(rand(seed) * 2.0 - 1.0, rand(seed) * 2.0 - 1.0, rand(seed) * 2.0 - 1.0);
	vec3 accumCol = vec3(0.0);
        vec3 mask = vec3(1.0);
        Intersection intersec;
	bool bounceIsSpecular = true;
	int sampleDiffuseBudget = 2;
	Quad lightChoice;
	
	if (rand(seed) < 0.5)
		lightChoice = quads[0];
	else lightChoice = quads[1];
	
	
        for (int depth = 0; depth < 4; depth++)
	{
		sampleDiffuseBudget -= 1;
		
		float t = SceneIntersect(r, intersec);
		
		if (t == INFINITY)
		{
                        break;
		}
		
		// if we reached something bright, don't spawn any more rays
		if (intersec.type == LIGHT)
		{	
			if (bounceIsSpecular)
			{
				accumCol = mask * intersec.emission;
			}
			
			break;
		}
		
		
		// useful data 
		vec3 n = intersec.normal;
                vec3 nl = dot(n,r.direction) <= 0.0 ? normalize(n) : normalize(n * -1.0);
		vec3 x = r.origin + r.direction * t;
		
		
                if (intersec.type == DIFF || intersec.type == CLOTH ) // Ideal DIFFUSE reflection
		{
			if (intersec.type == CLOTH)
				intersec.color *= texture2D(tClothTexture, (10.0 * x.xz) / 512.0).rgb;
			
			mask *= intersec.color;
			accumCol += calcDirectLightingQuad(mask, x, nl, lightChoice, seed);
                        bounceIsSpecular = false;
			
			sampleDiffuseBudget -= 1;
			if (sampleDiffuseBudget < 0) break;
			
			// choose random Diffuse sample vector
			r = Ray( x, randomCosWeightedDirectionInHemisphere(nl, seed) );
			r.origin += r.direction;
			//mask *= max(0.0, dot(r.direction, nl));
			
			continue;
		}
		
		if (intersec.type == SPEC)  // Ideal SPECULAR reflection
		{	
			mask *= intersec.color;
			
			r = Ray( x, reflect(r.direction, nl) );
			r.origin += r.direction;
			bounceIsSpecular = true;
			continue;
		}
		
		if (intersec.type == COAT)  // Diffuse object underneath with ClearCoat on top
		{	
			float IoR = 1.5;
			
			// Schlick Fresnel approx.
			float ddn = dot(-r.direction, nl);
			float nc = 1.0; // IOR of air
			float nt = IoR; // IOR of ClearCoat 
			float R0 = (nc - nt) / (nc + nt);
			R0 *= R0;
			float c = 1.0 - ddn;
			float Re = R0 + (1.0 - R0) * c * c * c * c * c;
			
			// choose either specular reflection or diffuse
			if( rand(seed) < Re )
			{	
				vec3 reflectVec = reflect(r.direction, nl);
				r = Ray( x, mix( reflectVec, normalize(nl + randVec), intersec.roughness) );
				r.origin += r.direction;
				bounceIsSpecular = true;
				continue;	
			}
			else
			{
				mask *= intersec.color;
				accumCol += calcDirectLightingQuad(mask, x, nl, lightChoice, seed);
				// choose random sample vector for diffuse material underneath ClearCoat
				r = Ray( x, randomCosWeightedDirectionInHemisphere(nl, seed) );
				r.origin += r.direction;
				//mask *= max(0.0, dot(r.direction, nl));
				bounceIsSpecular = false;
				continue;
			}
			
		} //end if (intersec.type == COAT)
		
		if (intersec.type == LIGHTWOOD || intersec.type == DARKWOOD)  // Diffuse object underneath with thin ClearCoat on top
		{
			float IoR = 1.1;
			
			// Schlick Fresnel approx.
			float ddn = dot(-r.direction, nl);
			float nc = 1.0; // IOR of air
			float nt = IoR; // IOR of ClearCoat 
			float R0 = (nc - nt) / (nc + nt);
			R0 *= R0;
			float c = 1.0 - ddn;
			float Re = R0 + (1.0 - R0) * c * c * c * c * c;
			
			// choose either specular reflection or diffuse
			if ( rand(seed) < Re )
			{	
				vec3 reflectVec = reflect(r.direction, nl);
				r = Ray( x, mix( reflectVec, normalize(nl + randVec), intersec.roughness) );
				r.origin += r.direction;
				bounceIsSpecular = true;
				continue;	
			}
			else
			{
				float spotRadius = 1.5;
				bool isSpot = false;
				
				bool spotn1 = distance(x, vec3(212, 10, -100)) < spotRadius;
				bool spotn2 = distance(x, vec3(212, 10, -200)) < spotRadius;
				bool spotn3 = distance(x, vec3(212, 10, -300)) < spotRadius;
				bool spotn4 = distance(x, vec3(212, 10, -400)) < spotRadius;
				bool spotp0 = distance(x, vec3(212, 10, 0)) < spotRadius;
				bool spotp1 = distance(x, vec3(212, 10, 100)) < spotRadius;
				bool spotp2 = distance(x, vec3(212, 10, 200)) < spotRadius;
				bool spotp3 = distance(x, vec3(212, 10, 300)) < spotRadius;
				bool spotp4 = distance(x, vec3(212, 10, 400)) < spotRadius;
				if (spotn1 || spotn2 || spotn3 || spotn4 || spotp0 || 
				    spotp1 || spotp2 || spotp3 || spotp4 ) 
				    	isSpot = true;
					
				spotn1 = distance(x, vec3(-212, 10, -100)) < spotRadius;
				spotn2 = distance(x, vec3(-212, 10, -200)) < spotRadius;
				spotn3 = distance(x, vec3(-212, 10, -300)) < spotRadius;
				spotn4 = distance(x, vec3(-212, 10, -400)) < spotRadius;
				bool spotn0 = distance(x, vec3(-212, 10, 0)) < spotRadius;
				spotp1 = distance(x, vec3(-212, 10, 100)) < spotRadius;
				spotp2 = distance(x, vec3(-212, 10, 200)) < spotRadius;
				spotp3 = distance(x, vec3(-212, 10, 300)) < spotRadius;
				spotp4 = distance(x, vec3(-212, 10, 400)) < spotRadius;
				if (spotn1 || spotn2 || spotn3 || spotn4 || spotn0 || 
				    spotp1 || spotp2 || spotp3 || spotp4 ) 
				    	isSpot = true;
				
				spotn1 = distance(x, vec3(200, 10, -412)) < spotRadius;
				spotn2 = distance(x, vec3(100, 10, -412)) < spotRadius;
				spotn0 = distance(x, vec3(0, 10, -412)) < spotRadius;
				spotn3 = distance(x, vec3(-100, 10, -412)) < spotRadius;
				spotn4 = distance(x, vec3(-200, 10, -412)) < spotRadius;
				spotp1 = distance(x, vec3(200, 10,  412)) < spotRadius;
				spotp2 = distance(x, vec3(100, 10, 412)) < spotRadius;
				spotp0 = distance(x, vec3(0, 10, 412)) < spotRadius;
				spotp3 = distance(x, vec3(-100, 10, 412)) < spotRadius;
				spotp4 = distance(x, vec3(-200, 10, 412)) < spotRadius;
				if (spotn1 || spotn2 || spotn0 || spotn3 || spotn4 || 
				    spotp1 || spotp2 || spotp0 || spotp3 || spotp4 ) 
				    	isSpot = true;
				
				if (intersec.type == DARKWOOD)
					intersec.color *= texture2D(tDarkWoodTexture, 3.5 * x.xz / 512.0).rgb;
					
				if (isSpot)
					intersec.color = clamp(intersec.color + 0.5, 0.0, 1.0);
					
				if (intersec.type == LIGHTWOOD)
					intersec.color *= texture2D(tLightWoodTexture, 6.0 * x.xz / 512.0).rgb;
					
				
				mask *= intersec.color;
				accumCol += calcDirectLightingQuad(mask, x, nl, lightChoice, seed);
				
				// choose random sample vector for diffuse material underneath ClearCoat
				r = Ray( x, randomCosWeightedDirectionInHemisphere(nl, seed) );
				r.origin += r.direction;
				//mask *= max(0.0, dot(r.direction, nl));
				bounceIsSpecular = false;
				continue;
			}
			
		} //end if (intersec.type == LIGHTWOOD || intersec.type == DARKWOOD)
		
		
	} // end for (int depth = 0; depth < 4; depth++)
	
	return accumCol;      
}


//-----------------------------------------------------------------------
void SetupScene(void)
//-----------------------------------------------------------------------
{
	vec3 z  = vec3(0);          
	vec3 L1 = vec3(1.2, 1.1, 1.0) * 4.0;// Bright White light
	vec3 clothColor = vec3(0.0, 0.2, 0.9);
	vec3 railWoodColor = vec3(0.05,0.0,0.0);
	float ceilingHeight = 300.0;
	
	quads[0] = Quad( vec3(0,-1, 0), vec3(-150, ceilingHeight,-300), vec3(-50, ceilingHeight,-300), vec3(-50, ceilingHeight,300), vec3(-150, ceilingHeight,300), L1, z, 0.0, LIGHT);// rectangular Area Light in ceiling
	quads[1] = Quad( vec3(0,-1, 0), vec3(50, ceilingHeight,-300), vec3(150, ceilingHeight,-300), vec3(150, ceilingHeight,300), vec3(50, ceilingHeight,300), L1, z, 0.0, LIGHT);// rectangular Area Light in ceiling
	quads[2] = Quad( normalize(vec3(1,-1, 0)), vec3(-200,0,-400), vec3(-190,10,-400), vec3(-190,10,400), vec3(-200,0,400), z, clothColor, 0.0, CLOTH);// Cloth left Rail bottom portion
	quads[3] = Quad( normalize(vec3(-1,-1, 0)), vec3(190,10,-400), vec3(200,0,-400),  vec3(200,0,400), vec3(190,10,400), z, clothColor, 0.0, CLOTH);// Cloth right Rail bottom portion
	quads[4] = Quad( normalize(vec3(0,-1, 1)), vec3(-200,0,-400), vec3(200,0,-400), vec3(200,10,-390), vec3(-200,10,-390), z, clothColor, 0.0, CLOTH);// Cloth back Rail bottom portion
	quads[5] = Quad( normalize(vec3(0,-1, -1)), vec3(200,0,400), vec3(-200,0,400),  vec3(-200,10,390), vec3(200,10,390), z, clothColor, 0.0, CLOTH);// Cloth front Rail bottom portion
	
	spheres[0] = Sphere(9.0, vec3( 25, 9, 25), z, vec3(0.8, 0.75, 0.7), 0.0, COAT);// White Ball
	spheres[1] = Sphere(9.0, vec3(-50, 9, 0),   z, vec3(0.9, 0.6, 0.1), 0.0, COAT);// Yellow Ball
	spheres[2] = Sphere(9.0, vec3( 50, 9, 0), z, vec3(0.4, 0.01, 0.01), 0.0, COAT);// Red Ball
        
	ellipsoids[0] = Ellipsoid(  vec3(1.97,1.97,1), vec3(0,2,79), z, vec3(0,0.3,0.7), 0.0, DIFF);//CueStick blue chalked tip
	ellipsoids[1] = Ellipsoid(  vec3(4.5,4.5,2), vec3(0,4.5,-375), z, vec3(0.01), 0.0, DIFF);//CueStick rubber butt-end cap
	
	boxes[0] = Box( vec3(-200,-10,-400), vec3(200,0,400), z, clothColor, 0.0, CLOTH);//Blue Cloth Table Bed
	boxes[1] = Box( vec3(-200,9,-400), vec3( 200, 10,-390), z, clothColor, 0.0, CLOTH);//Cloth Rail back
	boxes[2] = Box( vec3(-200,9, 390), vec3( 200, 10, 400), z, clothColor, 0.0, CLOTH);//Cloth Rail front
	boxes[3] = Box( vec3(-200,9,-400), vec3(-190, 10, 400), z, clothColor, 0.0, CLOTH);//Cloth Rail left
	boxes[4] = Box( vec3( 190,9,-400), vec3( 200, 10, 400), z, clothColor, 0.0, CLOTH);//Cloth Rail right
	
	boxes[5] = Box( vec3(-225,-10,-425), vec3( 225, 10,-400), z, railWoodColor, 0.3, DARKWOOD);//Wooden Rail back
	boxes[6] = Box( vec3(-225,-10, 400), vec3( 225, 10, 425), z, railWoodColor, 0.3, DARKWOOD);//Wooden Rail front
	boxes[7] = Box( vec3(-225,-10,-425), vec3(-200, 10, 425), z, railWoodColor, 0.3, DARKWOOD);//Wooden Rail left
	boxes[8] = Box( vec3( 200,-10,-425), vec3( 225, 10, 425), z, railWoodColor, 0.3, DARKWOOD);//Wooden Rail right
	
	planes[0] = Plane( vec4( 0,1,0, -300.0), z, vec3(0.5), 0.0, DIFF);//Floor
	
	cones[0] = Cone( vec3(0,3.5,-160), 3.5, vec3(0,2,72), 2.0, z, vec3(0.7), 0.1, LIGHTWOOD);//Wooden CueStick shaft
	cones[1] = Cone( vec3(0,2,71), 2.0, vec3(0,2,78), 1.97, z, vec3(0.9), 0.0, COAT);//CueStick shaft white plastic collar
	cones[2] = Cone( vec3(0,2,77.5), 1.93, vec3(0,2,79), 1.93, z, vec3(0.02,0.005,0.001), 0.4, COAT);//CueStick dark leather tip
	cones[3] = Cone( vec3(0,4,-270), 4.0, vec3(0,3.5,-160), 3.5, z, vec3(0.4, 0.01, 0.3), 0.0, DARKWOOD);//Wooden CueStick butt
	cones[4] = Cone( vec3(0,4.5,-375), 4.5, vec3(0,4,-270), 4.0, z, vec3(0.1), 0.0, CLOTH);//CueStick handle wrap
}


#include <pathtracing_main>


		</script>
		
		
		<script>
			
			var SCREEN_WIDTH;
			var SCREEN_HEIGHT;
			var container, stats;
			var controls;
			var pathTracingScene, screenTextureScene, screenOutputScene;
			var pathTracingUniforms, screenTextureUniforms, screenOutputUniforms;
			var clothTexture, darkWoodTexture, lightWoodTexture;
			var pathTracingDefines;
			var pathTracingGeometry, pathTracingMaterial, pathTracingMesh;
			var screenTextureGeometry, screenTextureMaterial, screenTextureMesh;
			var screenOutputGeometry, screenOutputMaterial, screenOutputMesh;
			var tallBoxGeometry, tallBoxMaterial, tallBoxMesh;
			var shortBoxGeometry, shortBoxMaterial, shortBoxMesh;
			var pathTracingRenderTarget, screenOutputRenderTarget;
			var quadCamera, worldCamera;
			var renderer, clock;
			var frameTime, elapsedTime;
			var fovScale;
			var increaseFOV = false;
			var decreaseFOV = false;
			var apertureSize = 0.0;
			var increaseAperture = false;
			var decreaseAperture = false;
			var focusDistance = 132.0;
			var increaseFocusDist = false;
			var decreaseFocusDist = false;
			var pixelRatio = 0.5;
			var TWO_PI = Math.PI * 2;
			var randomVector = new THREE.Vector3();
			var sampleCounter = 1.0;
			var keyboard = new THREEx.KeyboardState();
			var cameraIsMoving = false;
			var cameraJustStartedMoving = false;
			var cameraRecentlyMoving = false;
			var isPaused = true;
			var oldYawRotation, oldPitchRotation;
			var mobileJoystickControls = null;
			var oldDeltaX = 0, oldDeltaY = 0;
			var newDeltaX = 0, newDeltaY = 0;
			var mobileControlsMoveX = 0;
			var mobileControlsMoveY = 0;
			var stillFlagX = true, stillFlagY = true;
			var oldPinchWidthX = 0;
			var oldPinchWidthY = 0;
			var pinchDeltaX = 0;
			var pinchDeltaY = 0;
			var camFlightSpeed = 100;
			var fontAspect;
			
			// the following variables will be used to calculate rotations and directions from the camera
			var cameraDirectionVector = new THREE.Vector3();//for moving where the camera is looking
			var cameraRightVector = new THREE.Vector3();//for strafing the camera right and left
			var cameraUpVector = new THREE.Vector3();//for moving camera up and down
			var cameraWorldQuaternion = new THREE.Quaternion();//for rotating scene objects to match camera's current rotation
			var cameraControlsObject;//for positioning and moving the camera itself
			var cameraControlsYawObject;//allows access to control camera's left/right movements through mobile input
			var cameraControlsPitchObject;//allows access to control camera's up/down movements through mobile input

			var PI_2 = Math.PI / 2;//used by controls below
			
			var infoElement = document.getElementById( 'info' );
			infoElement.style.cursor = "default";
			infoElement.style.webkitUserSelect = "none";
			infoElement.style.MozUserSelect = "none";
			
			var cameraInfoElement = document.getElementById( 'cameraInfo' );
			cameraInfoElement.style.cursor = "default";
			cameraInfoElement.style.webkitUserSelect = "none";
			cameraInfoElement.style.MozUserSelect = "none";
			
			var mouseControl = true;
			
			
			function onMouseWheel( event ) {

				event.preventDefault();
				event.stopPropagation();

				if ( event.deltaY > 0 ) {
					
					increaseFOV = true;
				
				} else if ( event.deltaY < 0 ) {
					
					decreaseFOV = true;
					
				}

			}
			
			
			init();
			
			
		     // function init( meshes ) {
			function init() {
				
				if ( 'createTouch' in document ) {
					mouseControl = false;
					pixelRatio = 0.5;

					mobileJoystickControls = new MobileJoystickControls ({
						//showJoystick: true,
						enableMultiTouch: true
					});	
				}

				// if on mobile device, unpause the app because there is no ESC key and no mouse capture to do
				if ( !mouseControl )
					isPaused = false;

				if (mouseControl) {

					window.addEventListener( 'wheel', onMouseWheel, false );

					document.body.addEventListener("click", function() {
						this.requestPointerLock = this.requestPointerLock || this.mozRequestPointerLock;
						this.requestPointerLock();
					}, false);

					window.addEventListener("click", function(event) {
						event.preventDefault();	
					}, false);
					window.addEventListener("dblclick", function(event) {
						event.preventDefault();	
					}, false);


					var pointerlockChange = function ( event ) {

						if ( document.pointerLockElement === document.body || 
						    document.mozPointerLockElement === document.body || document.webkitPointerLockElement === document.body ) {

							isPaused = false;

						} else {

							isPaused = true;

						}

					};

					// Hook pointer lock state change events
					document.addEventListener( 'pointerlockchange', pointerlockChange, false );
					document.addEventListener( 'mozpointerlockchange', pointerlockChange, false );
					document.addEventListener( 'webkitpointerlockchange', pointerlockChange, false );

				}
				
				renderer = new THREE.WebGLRenderer();
				renderer.autoClear = false;
				// 1 is full resolution, 0.5 is half, 0.25 is quarter, etc. (must be > than 0.0)
				renderer.setPixelRatio(pixelRatio);
				renderer.setSize( window.innerWidth, window.innerHeight );
				renderer.context.getExtension('OES_texture_float');
				
				container = document.getElementById( 'container' );
				container.appendChild( renderer.domElement );
				
				stats = new Stats();
				stats.domElement.style.position = 'absolute';
				stats.domElement.style.top = '0px';
				stats.domElement.style.cursor = "default";
				stats.domElement.style.webkitUserSelect = "none";
				stats.domElement.style.MozUserSelect = "none";
				container.appendChild( stats.domElement );
				
				window.addEventListener( 'resize', onWindowResize, false );
				
				clock = new THREE.Clock();
				
				pathTracingScene = new THREE.Scene();
				screenTextureScene = new THREE.Scene();
				screenOutputScene = new THREE.Scene();
				
				// quadCamera is simply the camera to help render the full screen quad (2 triangles),
				// hence the name.  It is an Orthographic camera that sits facing the view plane, which serves as
				// the window into our 3d world. This camera will not move or rotate for the duration of the app.
				quadCamera = new THREE.OrthographicCamera( -1, 1, 1, -1, 0, 1 );
				screenTextureScene.add(quadCamera);
				screenOutputScene.add(quadCamera);
				
				// worldCamera is the dynamic camera 3d object that will be positioned, oriented and 
				// constantly updated inside the 3d scene.  Its view will ultimately get passed back to the 
				// stationary quadCamera, which renders the scene to a fullscreen quad (made up of 2 large triangles).
				worldCamera = new THREE.PerspectiveCamera(55, window.innerWidth / window.innerHeight, 1, 1000);
				pathTracingScene.add(worldCamera);
				
				controls = new FirstPersonCameraControls( worldCamera );
							
				cameraControlsObject = controls.getObject();
				cameraControlsYawObject = controls.getYawObject();
				cameraControlsPitchObject = controls.getPitchObject();
				
				pathTracingScene.add( cameraControlsObject );
				
				// for flyCam
				// set camera position
				cameraControlsObject.position.set(100,50,140);
				// look left
				cameraControlsYawObject.rotation.y = 0.6;
				// look slightly downward
				cameraControlsPitchObject.rotation.x = -0.2;
				
				oldYawRotation = cameraControlsYawObject.rotation.y;
				oldPitchRotation = cameraControlsPitchObject.rotation.x;
				
				// now that we moved and rotated the camera, the following line force-updates the camera's matrix,
				//  and prevents rendering the very first frame in the old default camera position/orientation
				cameraControlsObject.updateMatrixWorld(true);
				
				pathTracingRenderTarget = new THREE.WebGLRenderTarget( (window.innerWidth * pixelRatio), (window.innerHeight * pixelRatio), {
					minFilter: THREE.NearestFilter,
					magFilter: THREE.NearestFilter,
					format: THREE.RGBAFormat,
					type: THREE.FloatType,
					depthBuffer: false,
					stencilBuffer: false
				} );
				pathTracingRenderTarget.texture.generateMipmaps = false;
				
				screenTextureRenderTarget = new THREE.WebGLRenderTarget( (window.innerWidth * pixelRatio), (window.innerHeight * pixelRatio), {
					minFilter: THREE.NearestFilter, 
					magFilter: THREE.NearestFilter,
					format: THREE.RGBAFormat,
					type: THREE.FloatType,
					depthBuffer: false,
					stencilBuffer: false
				} );
				screenTextureRenderTarget.texture.generateMipmaps = false;
				
				clothTexture = new THREE.TextureLoader().load( 'textures/cloth.jpg' );
				clothTexture.wrapS = THREE.RepeatWrapping;
				clothTexture.wrapT = THREE.RepeatWrapping;
				clothTexture.flipY = false;
				//clothTexture.minFilter = THREE.LinearMipMapLinearFilter; 
				//clothTexture.magFilter = THREE.LinearFilter;
				//clothTexture.generateMipmaps = false;
				
				darkWoodTexture = new THREE.TextureLoader().load( 'textures/darkWood.jpg' );
				darkWoodTexture.wrapS = THREE.RepeatWrapping;
				darkWoodTexture.wrapT = THREE.RepeatWrapping;
				darkWoodTexture.flipY = false;
				//darkWoodTexture.minFilter = THREE.LinearFilter; 
				//darkWoodTexture.magFilter = THREE.LinearFilter;
				//darkWoodTexture.generateMipmaps = false;
				
				lightWoodTexture = new THREE.TextureLoader().load( 'textures/lightWood.jpg' );
				lightWoodTexture.wrapS = THREE.RepeatWrapping;
				lightWoodTexture.wrapT = THREE.RepeatWrapping;
				lightWoodTexture.flipY = false;
				//lightWoodTexture.minFilter = THREE.LinearFilter; 
				//lightWoodTexture.magFilter = THREE.LinearFilter;
				//lightWoodTexture.generateMipmaps = false;
				
				
				pathTracingGeometry = new THREE.PlaneBufferGeometry( 2, 2 );

				pathTracingUniforms = {
					
					tPreviousTexture: { type: "t", value: screenTextureRenderTarget.texture },
					tClothTexture: { type: "t", value: clothTexture },
					tDarkWoodTexture: { type: "t", value: darkWoodTexture },
					tLightWoodTexture: { type: "t", value: lightWoodTexture },
					
					uCameraIsMoving: { type: "b1", value: false },
					uCameraJustStartedMoving: { type: "b1", value: false },
					uTime: { type: "f", value: 0.0 },
					uSampleCounter: { type: "f", value: 0.0 },
					uULen: { type: "f", value: 1.0 },
					uVLen: { type: "f", value: 1.0 },
					uApertureSize: { type: "f", value: 0.0 },
					uFocusDistance: { type: "f", value: 132.0 },
					
					uResolution: { type: "v2", value: new THREE.Vector2() },
					
					uRandomVector: { type: "v3", value: new THREE.Vector3() },
				
					uCameraMatrix: { type: "m4", value: new THREE.Matrix4() }
	
				};
				
				/*
				pathTracingDefines = {
					NUMBER_OF_TRIANGLES: total_number_of_triangles
				};
				*/
			
				pathTracingMaterial = new THREE.ShaderMaterial( {
					uniforms: pathTracingUniforms,
					//defines: pathTracingDefines,
					vertexShader: document.getElementById( 'pathTracingVertexShader' ).textContent,
					fragmentShader: document.getElementById( 'pathTracingFragmentShader' ).textContent,
				        depthTest: false,
                                        depthWrite: false
                                } );

				pathTracingMesh = new THREE.Mesh( pathTracingGeometry, pathTracingMaterial );
				pathTracingScene.add( pathTracingMesh );
				
				
				
				// the following keeps the large scene ShaderMaterial quad right in front 
				//   of the camera at all times. This is necessary because without it, the scene 
				//   quad will fall out of view and get clipped when the camera rotates past 180 degrees.
				worldCamera.add( pathTracingMesh );
				
				
				
				screenTextureGeometry = new THREE.PlaneBufferGeometry( 2, 2 );
				
				screenTextureMaterial = new THREE.ShaderMaterial( {
					uniforms: screenTextureShader.uniforms,
					vertexShader: screenTextureShader.vertexShader,
					fragmentShader: screenTextureShader.fragmentShader,
					depthWrite: false,
					depthTest: false
				} );
				
				screenTextureMaterial.uniforms.tTexture0.value = pathTracingRenderTarget.texture;
				
				screenTextureMesh = new THREE.Mesh(screenTextureGeometry, screenTextureMaterial);
				screenTextureScene.add(screenTextureMesh);
				
				
				
				screenOutputGeometry = new THREE.PlaneBufferGeometry( 2, 2 );
				
				screenOutputMaterial = new THREE.ShaderMaterial( {
					uniforms: screenOutputShader.uniforms,
					vertexShader: screenOutputShader.vertexShader,
					fragmentShader: screenOutputShader.fragmentShader,
					depthWrite: false,
					depthTest: false
				} );
				
				screenOutputMaterial.uniforms.tTexture0.value = pathTracingRenderTarget.texture;
				
				screenOutputMesh = new THREE.Mesh(screenOutputGeometry, screenOutputMaterial);
				screenOutputScene.add(screenOutputMesh);
				
				
				/*
				// Fullscreen API
				document.addEventListener("click", function() {
					
					if ( !document.fullscreenElement && !document.mozFullScreenElement && !document.webkitFullscreenElement ) {

						if (document.documentElement.requestFullscreen) {
							document.documentElement.requestFullscreen();
							
						} else if (document.documentElement.mozRequestFullScreen) {
							document.documentElement.mozRequestFullScreen();
						
						} else if (document.documentElement.webkitRequestFullscreen) {
							document.documentElement.webkitRequestFullscreen();
						
						}

					}
				});
				*/
				
				// onWindowResize() must be at the end of the init() function
				onWindowResize();
				
				// everything is set up, now we can start animating
				animate();
				
			} // end function init()
			
			
			
			function onWindowResize( event ) {
				
				SCREEN_WIDTH = window.innerWidth;
				SCREEN_HEIGHT = window.innerHeight;
				
				renderer.setPixelRatio(pixelRatio);
				renderer.setSize( SCREEN_WIDTH, SCREEN_HEIGHT );
				
				fontAspect = (SCREEN_WIDTH / 175) * (SCREEN_HEIGHT / 200);
				if (fontAspect > 25) fontAspect = 25;
				if (fontAspect < 4) fontAspect = 4;
				fontAspect *= 2;
				
				pathTracingUniforms.uResolution.value.x = renderer.context.drawingBufferWidth;
				pathTracingUniforms.uResolution.value.y = renderer.context.drawingBufferHeight;
				
				pathTracingRenderTarget.setSize( renderer.context.drawingBufferWidth, renderer.context.drawingBufferHeight );
				screenTextureRenderTarget.setSize( renderer.context.drawingBufferWidth, renderer.context.drawingBufferHeight );
				
				worldCamera.aspect = renderer.domElement.clientWidth / renderer.domElement.clientHeight;
				worldCamera.updateProjectionMatrix();
				
				// the following scales all scene objects by the worldCamera's field of view,
				// taking into account the screen aspect ratio and multiplying the uniform uULen,
				// the x-coordinate, by this ratio
				fovScale = worldCamera.fov * 0.5 * (Math.PI / 180.0);
				pathTracingUniforms.uVLen.value = Math.tan(fovScale);
				pathTracingUniforms.uULen.value = pathTracingUniforms.uVLen.value * worldCamera.aspect;
				
				if ( !mouseControl ) {
					
					button1Element.style.display = "";
					button2Element.style.display = "";
					button3Element.style.display = "";
					button4Element.style.display = "";
					button5Element.style.display = "";
					button6Element.style.display = "";
					// check if mobile device is in portrait or landscape mode and position buttons accordingly
					if (SCREEN_WIDTH < SCREEN_HEIGHT) {
						
						button1Element.style.right = 36 + "%";
						button2Element.style.right = 2 + "%";
						button3Element.style.right = 16 + "%";
						button4Element.style.right = 16 + "%";
						button5Element.style.right = 3 + "%";
						button6Element.style.right = 3 + "%";

						button1Element.style.bottom = 5 + "%";
						button2Element.style.bottom = 5 + "%";
						button3Element.style.bottom = 13 + "%";
						button4Element.style.bottom = 2 + "%";
						button5Element.style.bottom = 25 + "%";
						button6Element.style.bottom = 18 + "%";
						
					}
					else {
						
						button1Element.style.right = 22 + "%";
						button2Element.style.right = 3 + "%";
						button3Element.style.right = 11 + "%";
						button4Element.style.right = 11 + "%";
						button5Element.style.right = 3 + "%";
						button6Element.style.right = 3 + "%";

						button1Element.style.bottom = 10 + "%";
						button2Element.style.bottom = 10 + "%";
						button3Element.style.bottom = 26 + "%";
						button4Element.style.bottom = 4 + "%";
						button5Element.style.bottom = 48 + "%";
						button6Element.style.bottom = 34 + "%";
						
					}
					
				} // end if ( !mouseControl ) {
				
			} // end function onWindowResize( event )
			
			
			
			function animate() {
				
				requestAnimationFrame( animate );
				
				frameTime = clock.getDelta();
				
				//elapsedTime = clock.getElapsedTime() % 1000;
				
				// reset flags
				cameraIsMoving = false;
				cameraJustStartedMoving = false;
				
				// check user controls
				if (mouseControl) {
					// movement detected
					if ( oldYawRotation != cameraControlsYawObject.rotation.y || 
					      oldPitchRotation != cameraControlsPitchObject.rotation.x ) {
	
						cameraIsMoving = true;
					}
					
					// save state for next frame
					oldYawRotation = cameraControlsYawObject.rotation.y;
					oldPitchRotation = cameraControlsPitchObject.rotation.x;
					
				} // end if (mouseControl)
			
				// if not playing on desktop, get input from the mobileJoystickControls
				if ( !mouseControl ) {

					newDeltaX = joystickDeltaX;
					
					if (newDeltaX) {
						
						mobileControlsMoveX = oldDeltaX - newDeltaX;
						// smooth out jerkiness if camera was sitting still 
						if (stillFlagX) {
							mobileControlsMoveX *= 0.1;
							stillFlagX = false;
						}
						// mobileJoystick X movement (left and right) affects camera rotation around the Y axis	
						cameraControlsYawObject.rotation.y += (mobileControlsMoveX) * 0.01;
					}
					
					newDeltaY = joystickDeltaY;
					
					if (newDeltaY) {
						
						mobileControlsMoveY = oldDeltaY - newDeltaY;
						// smooth out jerkiness if camera was sitting still
						if (stillFlagY) {
							mobileControlsMoveY *= 0.1;
							stillFlagY = false;
						}
						// mobileJoystick Y movement (up and down) affects camera rotation around the X axis	
						cameraControlsPitchObject.rotation.x += (mobileControlsMoveY) * 0.01;
					}
					
					// clamp the camera's vertical movement (around the x-axis) to the scene's 'ceiling' and 'floor',
					// so you can't accidentally flip the camera upside down
					cameraControlsPitchObject.rotation.x = Math.max( - PI_2, Math.min( PI_2, cameraControlsPitchObject.rotation.x ) );
					
					// save state for next frame
					oldDeltaX = newDeltaX;
					oldDeltaY = newDeltaY;
					
					// movement detected
					if ( newDeltaX || newDeltaY ) {
						
						cameraIsMoving = true;
					}
					else {
						stillFlagX = true;
						stillFlagY = true;
					}
					
					newPinchWidthX = pinchWidthX;
					newPinchWidthY = pinchWidthY;
					pinchDeltaX = newPinchWidthX - oldPinchWidthX;
					pinchDeltaY = newPinchWidthY - oldPinchWidthY;
					
					if( Math.abs(pinchDeltaX) > Math.abs(pinchDeltaY) ) {
						if (pinchDeltaX < -3) increaseFOV = true;
						if (pinchDeltaX >  3) decreaseFOV = true;
					}
					
					if( Math.abs(pinchDeltaY) >= Math.abs(pinchDeltaX) ) {
						if (pinchDeltaY >  1) increaseAperture = true;
						if (pinchDeltaY < -1) decreaseAperture = true;
					}
					
					// save state for next frame
					oldPinchWidthX = newPinchWidthX;
					oldPinchWidthY = newPinchWidthY;
					
				} // end if ( !mouseControl )
				
				// this gives us a vector in the direction that the camera is pointing,
				// which will be useful for moving the camera 'forward' and shooting projectiles in that direction
				controls.getDirection(cameraDirectionVector);
				cameraDirectionVector.normalize();
				controls.getUpVector(cameraUpVector);
				controls.getRightVector(cameraRightVector);

				// the following gives us a rotation quaternion (4D vector), which will be useful for 
				// rotating scene objects to match the camera's rotation
				worldCamera.getWorldQuaternion(cameraWorldQuaternion);
				
				// allow flying camera
				if ( (keyboard.pressed('W') || button3Pressed) && !(keyboard.pressed('S') || button4Pressed) ) {

					cameraControlsObject.position.add(cameraDirectionVector.multiplyScalar(camFlightSpeed * frameTime));
					cameraIsMoving = true;
				}
				if ( (keyboard.pressed('S') || button4Pressed) && !(keyboard.pressed('W') || button3Pressed) ) {

					cameraControlsObject.position.sub(cameraDirectionVector.multiplyScalar(camFlightSpeed * frameTime));
					cameraIsMoving = true;
				}
				if ( (keyboard.pressed('A') || button1Pressed) && !(keyboard.pressed('D') || button2Pressed) ) {

					cameraControlsObject.position.sub(cameraRightVector.multiplyScalar(camFlightSpeed * frameTime));
					cameraIsMoving = true;
				}
				if ( (keyboard.pressed('D') || button2Pressed) && !(keyboard.pressed('A') || button1Pressed) ) {

					cameraControlsObject.position.add(cameraRightVector.multiplyScalar(camFlightSpeed * frameTime));
					cameraIsMoving = true;
				}
				if ( keyboard.pressed('Q') && !keyboard.pressed('Z') ) {

					cameraControlsObject.position.add(cameraUpVector.multiplyScalar(camFlightSpeed * frameTime));
					cameraIsMoving = true;
				}
				if ( keyboard.pressed('Z') && !keyboard.pressed('Q') ) {

					cameraControlsObject.position.sub(cameraUpVector.multiplyScalar(camFlightSpeed * frameTime));
					cameraIsMoving = true;
				}
				if ( (keyboard.pressed('up') || button5Pressed) && !(keyboard.pressed('down') || button6Pressed) ) {
					
					increaseFocusDist = true;
				}
				if ( (keyboard.pressed('down') || button6Pressed) && !(keyboard.pressed('up') || button5Pressed) ) {
					
					decreaseFocusDist = true;
				}
				if ( keyboard.pressed('right') && !keyboard.pressed('left') ) {
					
					increaseAperture = true;
				}
				if ( keyboard.pressed('left') && !keyboard.pressed('right') ) {
					
					decreaseAperture = true;
				}
				
				
				if ( increaseFOV ) {
					worldCamera.fov ++;
					if (worldCamera.fov > 150)
						worldCamera.fov = 150;
					fovScale = worldCamera.fov * 0.5 * (Math.PI / 180.0);
					pathTracingUniforms.uVLen.value = Math.tan(fovScale);
					pathTracingUniforms.uULen.value = pathTracingUniforms.uVLen.value * worldCamera.aspect;
				
					cameraIsMoving = true;
					increaseFOV = false;
				}
				if ( decreaseFOV ) {
					worldCamera.fov --;
					if (worldCamera.fov < 1)
						worldCamera.fov = 1;
					fovScale = worldCamera.fov * 0.5 * (Math.PI / 180.0);
					pathTracingUniforms.uVLen.value = Math.tan(fovScale);
					pathTracingUniforms.uULen.value = pathTracingUniforms.uVLen.value * worldCamera.aspect;
					
					cameraIsMoving = true;
					decreaseFOV = false;
				}
				
				if (increaseFocusDist) {
					focusDistance += 1;
					pathTracingUniforms.uFocusDistance.value = focusDistance;
					cameraIsMoving = true;
					increaseFocusDist = false;
				}
				if (decreaseFocusDist) {
					focusDistance -= 1;
					if (focusDistance < 1)
						focusDistance = 1;
					pathTracingUniforms.uFocusDistance.value = focusDistance;
					cameraIsMoving = true;
					decreaseFocusDist = false;
				}
				
				if (increaseAperture) {
					apertureSize += 0.1;
					if (apertureSize > 20.0)
						apertureSize = 20.0;
					pathTracingUniforms.uApertureSize.value = apertureSize;
					cameraIsMoving = true;
					increaseAperture = false;
				}
				if (decreaseAperture) {
					apertureSize -= 0.1;
					if (apertureSize < 0.0)
						apertureSize = 0.0;
					pathTracingUniforms.uApertureSize.value = apertureSize;
					cameraIsMoving = true;
					decreaseAperture = false;
				}
				
				
				if ( cameraIsMoving ) {
					
					sampleCounter = 1.0;
					
					if ( !cameraRecentlyMoving ) {
						cameraJustStartedMoving = true;
						cameraRecentlyMoving = true;
					}
					
				}
				
				if ( !cameraIsMoving ) {
	
					sampleCounter += 1.0;
					cameraRecentlyMoving = false;
					
				}
					
				
				pathTracingUniforms.uCameraIsMoving.value = cameraIsMoving;
				pathTracingUniforms.uCameraJustStartedMoving.value = cameraJustStartedMoving;
				pathTracingUniforms.uSampleCounter.value = sampleCounter;
				pathTracingUniforms.uRandomVector.value = randomVector.set( Math.random(), Math.random(), Math.random() );
				// CAMERA
				cameraControlsObject.updateMatrixWorld(true);			
				pathTracingUniforms.uCameraMatrix.value.copy( worldCamera.matrixWorld );
				screenOutputMaterial.uniforms.uOneOverSampleCounter.value = 1.0 / sampleCounter;
				
				cameraInfoElement.innerHTML = "FOV: " + worldCamera.fov + " / Aperture: " + apertureSize.toFixed(2) + " / FocusDistance: " + focusDistance + "<br>" + "Samples: " + sampleCounter;
				
				
				// RENDERING in 3 steps
				
				// STEP 1
				// Perform PathTracing and Render(save) into pathTracingRenderTarget
				// Read previous screenTextureRenderTarget to use as a new starting point to blend with
				renderer.render( pathTracingScene, worldCamera, pathTracingRenderTarget );	
				
				// STEP 2
				// Render(copy) the final pathTracingScene output(above) into screenTextureRenderTarget
				// This will be used as a new starting point for Step 1 above
				renderer.render( screenTextureScene, quadCamera, screenTextureRenderTarget );
				
				// STEP 3
				// Render full screen quad with generated pathTracingRenderTarget in STEP 1 above.
				// After the image is gamma corrected, it will be shown on the screen as the final accumulated output
				renderer.render( screenOutputScene, quadCamera );
						
				
				stats.update();
					
				
			} // end function animate()

		</script>

	</body>
</html>
